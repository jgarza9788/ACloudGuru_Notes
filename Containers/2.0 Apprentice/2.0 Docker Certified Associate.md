

**Exam Details:**

*   **Exam Title:** Docker Certified Associate
*   **Exam Code:** DCA
*   **Exam Duration:** 90 minutes
*   **Number of Questions:** Approximately 55-60 multiple-choice questions
*   **Passing Score:** 70%
*   **Exam Cost:** The cost may vary depending on your location and the testing center.

**Topics Covered:** The Docker Certified Associate exam covers a wide range of topics related to Docker and containerization. These topics include:

1.  **Docker Fundamentals:**
    
    *   Understanding containerization concepts.
    *   Docker architecture, components, and services.
    *   Basic Docker commands and operations.
2.  **Docker Installation and Configuration:**
    
    *   Installing and configuring Docker on various platforms.
    *   Managing Docker configurations and settings.
3.  **Container Management:**
    
    *   Creating, running, and managing Docker containers.
    *   Working with container images and Docker Hub.
4.  **Docker Networking:**
    
    *   Configuring and managing Docker networking.
    *   Understanding container communication and connectivity.
5.  **Docker Storage and Volumes:**
    
    *   Managing data persistence with Docker volumes.
    *   Understanding storage drivers and options.
6.  **Docker Compose:**
    
    *   Defining and managing multi-container applications using Docker Compose.
    *   Compose file structure and syntax.
7.  **Docker Security:**
    
    *   Securing Docker containers and images.
    *   Implementing security best practices.
    *   User authentication and authorization.
8.  **Docker Orchestration:**
    
    *   Introduction to Docker Swarm and Kubernetes.
    *   Deploying and managing containerized applications in an orchestrated environment.
9.  **Docker Logging and Monitoring:**
    
    *   Collecting and analyzing container logs.
    *   Implementing monitoring and alerting solutions.
10.  **Troubleshooting and Maintenance:**
    
    *   Diagnosing and troubleshooting common Docker issues.
    *   Performing regular maintenance tasks.

**Preparation:** To prepare for the Docker Certified Associate exam, consider the following steps:

1.  **Study the Official Documentation:** Review the Docker documentation thoroughly as it covers all the essential topics.
    
2.  **Hands-On Experience:** Gain practical experience by working with Docker containers and images.
    
3.  **Training Courses:** Consider taking Docker training courses or online tutorials.
    
4.  **Practice Exams:** Use practice exams and sample questions to assess your readiness.
    
5.  **Study Guides:** Explore study guides and books related to Docker certification.
    
6.  **Docker Playground:** Utilize Docker playgrounds or sandboxes to experiment with Docker in a risk-free environment.
    
7.  **Join the Community:** Participate in Docker communities and forums to ask questions and learn from others.
    

**Conclusion:** The Docker Certified Associate certification demonstrates your proficiency in Docker containerization technology. It's a valuable credential for professionals involved in container-based application development, deployment, and management. Prepare thoroughly, gain hands-on experience, and you'll be well-equipped to pass the DCA exam and further your career in containerization and DevOps.


---

# Course Features and Tools.txt

* Cloud Playground: Accessible through the "Playground" button, allows you to spin up cloud servers for hands-on learning.
* Hands-On Labs: Offers self-contained environments with temporary servers and step-by-step instructions.
* Course Scheduler: Helps create a study schedule for the course content.
* Flash Cards: Useful for memorization, especially important for the text-based multiple-choice Docker Certified Associate exam.
* Practice Exam: A multiple-choice exam similar to the Docker Certified Associate exam for preparation.
* Community Tab: Offers ways to connect with instructors and other students, ask questions, and provide assistance during the course.

---

# Docker Editions

* Docker Editions: Docker offers two editions, Community Edition (CE) and Enterprise Edition (EE).
* Docker CE: The free and open-source version of Docker Engine.
* Core Functionality: Docker CE provides core container functionality, including running containers, Docker Swarm, networking, and security.
* Feature Parity: Docker CE and EE have the same core features and receive updates on the same schedule.
* Emphasis: This section focuses on Docker Community Edition, covering installation, configuration, Docker Swarm, and basic Docker functionality.

---



* Docker CE Installation: This lesson demonstrates the installation of Docker Community Edition (CE) on a CentOS server.
* Server Setup: A CentOS 7 server is created in the cloud playground for installation.
* Required Packages: Device-mapper-persistent-data and lvm2 packages are installed as prerequisites.
* Adding Docker Repo: Docker CE repository is added using the yum-config-manager command.
* Docker Installation: Docker CE is installed with a specific version (18.09.5), along with docker-ce-cli and containerd.io.
* Docker Service Management: The Docker service is started and enabled using systemctl to ensure it runs on server startup.
* User Permissions: The cloud_user is added to the docker group to grant Docker command access.
* Testing Docker: Docker is verified by running a simple docker run command to execute a container.
* Successful Installation: The container runs successfully, confirming the Docker installation on CentOS.
* Next Steps: The lesson concludes with a preview of installing Docker CE on an Ubuntu environment in the next lesson.


# Installing Docker CE (CentOS)

To Install Docker CE on CentOS, we will
need to do the following:

* Provision a Server
    * Image: CentOS 7
    * Size: Small
* Install Required Packages: Install some
required packages (yum-utils, device-
mapper-persistent-data, and lvm2).
* Add the Docker Repo
* Install Docker and Containerd packages
* Start and Enable the Docker Service
* Configure cloud_user to be Able to Use
Docker: Add cloud user to the docker
group, then log out and back in.
* Run a Container to Test the
Installation: Test the installation by
running the hello-world image.

# Installing Docker CE (Ubuntu)

To Install Docker CE on Ubuntu, we will
need to do the following:

* Provision a Server
    * Image: Ubuntu 18.04 Bionic Beaver LTS
Size: Small
* Install Required Packages
* Add the Docker GPG Key and Repo
* Install Docker and Containerd packages
* Configure cloud_user to be Able to Use
Docker: Add cloud user to the docker
group, then log out and back in.
* Run a Container to Test the
Installation: Test the installation by
running the hello-world image.

---

# Selecting a Storage Driver

Storage drivers provide a pluggable
framework for managing the temporary,
internal storage of a container's writable
layer.
Docker supports a variety of storage
drivers. The best storage driver to use
depends on your environment and your
storage needs.
overlay2: File-based storage. Default for
Ubuntu and CentOS 8+.
devicemapper: Block storage, more
efficient for doing lots of writes. Default for
CentOS 7 and earlier.
You can find out what storage driver is
currently configured with docker info

# Selecting a Storage Driver

Docker automatically selects a default
storage driver that is compatible with your
environment.
However, in some cases you may want to
override the default to use a different
driver.
There are two ways to do this:
* Set the --storage-driver flag when
starting Docker (in your system unit file
for example).
"storage-driver" value in
* Set the
/etc/docker/daemon.json.

```bash

docker info
# shows the storage driver

# edit this file 
sudo vi /user/lib/systemd/system/docker.service
# change the storage driver
# in vi
--storage-driver devicemapper
# exit vi

# reload docker
sudo systemctl daemon-reload
sudo systemctl restart docker
docker info

# ^ undo this change above

# /////////////////////////////////

sudo vi /etc/docker/daemon.json
# in vi
{
    "system-driver": "devicemapper"
}
#exit vi

# reload docker
sudo systemctl daemon-reload
sudo systemctl restart docker
docker info

```

# running Containers

* Running Containers: This lesson focuses on running containers using the docker run command.
* Docker Run Basics: The basic structure of the docker run command is introduced, emphasizing the required elements: docker, run, and a reference to an image.
* Image Tags: Images can have tags, representing versions or variants. Without specifying a tag, Docker automatically chooses the latest version.
* Running Specific Commands: Demonstrates running containers with specific commands and arguments, allowing customization of container behavior.
* Detached Mode (-d): Explains the -d flag, used to run containers in detached mode, allowing them to run in the background and releasing the command prompt.
* Naming Containers (--name): Shows how to assign custom names to containers using the --name flag, making it easier to manage and reference them.
* Container Restart Policies (--restart): Discusses different restart policies (no, on-failure, always, unless-stopped) for controlling container restart behavior in various scenarios.
* Port Mapping (-p): Demonstrates using the -p flag to publish container ports, making them accessible from the host system or the network.
* Automatic Container Removal (--rm): Explains the --rm flag, which automatically deletes containers upon stopping, preventing lingering containers from taking up disk space.
* Memory Limits (--memory and --memory-reservation): Covers setting memory limits for containers using --memory and --memory-reservation flags.
* Listing Containers (docker ps and docker ps -a): Shows how to list currently running containers with docker ps and all containers (including stopped ones) with docker ps -a.
* Stopping and Starting Containers (docker container stop and docker container start): Illustrates stopping and starting containers using docker container stop and docker container start.
* Deleting Containers (docker container rm): Explains how to delete containers with docker container rm, ensuring that containers are first stopped if necessary.
* Managing Containers: Summarizes key container management commands and concepts learned in the lesson.


```bash

docker run hello-world
# runs a container in docker

docker run nginx:1.15.11
# runs nginx with tag

docker run busybox echo hello-world!
# starts a busybox with an hello-world command

docker run -d nginx 
# -d detatched mode (runs in background)
docker ps

docker container stop <id>


docker run -d --name nginx --restart always nginx 
# restart in an endless loop

docker run -d --name nginx --restart unless-stopped -p 8080:80 nginx 
# -p publish the port
# 8080 <- host part on the server
# 80 <- port for inside the container

# --rm : remove the container when done

#--memory 500M 
# memory limit

#--memory-reservation 256M
# memory reservation (should be less then the memory limit, if server is under a lot of load)

```


# Running a Container
Some commonly-used options:
* -d: Run container in detached mode.
The docker run command will exit
immediately and the container will run
in the background.

* --name: A container is assigned a
random name by default, but you can
give it a more descriptive name with this
flag.

* --restart: Specify when the container
should be automatically restarted.
    * no (default): Never restart the container.
    * on-failure: Only if the container fails (exits with a non-zero exit code).
    * always: Always restart the container whether it succeeds or fails. Also starts the container automatically on daemon startup.
    * unless-stopped: Always restart the container whether it succeeds or fails, and on daemon startup, unless the container was manually stopped.


[docker run documentation](https://docs.docker.com/engine/reference/run/)


```bash
docker ps
# list all active containers

curl localhost:8080

docker ps -a
# shows all the containers, even past containers

docker container stop <name or id>
docker container start <name of id>
docker container rm <name of id>
# stop the container before remove



```

## Upgrading Docker Engine: 
This lesson covers the process of upgrading the Docker Engine.
Initial State: The instructor is currently using Docker Community Edition version 18.09.5 on an Ubuntu Server.

## Downgrading: 
The instructor explains that they will first demonstrate downgrading Docker before proceeding with the upgrade.

## Steps to Downgrade:
Stop Docker: sudo systemctl stop docker.

## Remove Docker packages: 
sudo apt-get remove docker-ce docker-ce-cli.
Install an earlier version (downgrade): sudo apt-get install -y docker-ce=18.09.4 docker-ce-cli=18.09.4.

## Upgrading Docker: 
The instructor shows that upgrading Docker is simpler and does not require stopping Docker or removing packages.

## Steps to Upgrade:
Install the new version: sudo apt-get install -y docker-ce=18.09.5 docker-ce-cli=18.09.5.

## Confirmation: 
The instructor verifies the Docker version using the docker version command.

## Summary: 
The lesson demonstrates both the downgrade and upgrade processes for Docker, emphasizing that upgrading involves installing a newer version of Docker packages.


```bash

sudo systemctl stop docker

sudo apt-get remove -y docker-ce docker-ce-cli

sudo apt-get update

sudo apt-get install -y docker-ce=5:18.09.4~3-0~ubuntu-bionic docker-ce-cli=5:18.09.4~3-0~ubuntu-bionic

docker version

```


# Configuring Logging Drivers
Logging drivers are a pluggable framework
for accessing log data from services and
containers in Docker. Docker supports a
variety of logging drivers.

Configure the default logging driver by
setting log-driver and log-opts
in
/etc/docker/daemon.json

You override the default logging driver and
options for a container with the --log-driver
and --log-opt flags when using docker run.


Logging Drivers in Docker: 
This lesson covers the concept of logging drivers in Docker, which allows customization of log data handling for containers and services.

Variety of Logging Drivers: 
Docker supports various logging drivers, and users can choose from them based on their needs.

Default Logging Driver: 
Docker has a system-wide default logging driver, which can be overridden for individual containers.

No Need to Configure Default: 
Docker has a built-in logging driver configuration, so users don't need to configure it if the default is acceptable.

Setting Default Logging Driver: 
To set the default logging driver, edit the daemon.json file (usually located at /etc/docker/daemon.json) and specify the desired logging driver using the log-driver key.

Additional Logging Driver Configuration: 
Users can also configure additional options for logging drivers using the log-opts key.

Example: Demonstrates setting the default logging driver to json-file with a max size of 15 megabytes.

Restart Docker: After editing the daemon.json file, restart Docker for changes to take effect.

Overriding Logging Driver for Containers: Users can override the default logging driver for individual containers using the --log-driver flag with docker run.

Example: Runs an Nginx container with the syslog logging driver.
Overriding Logging Driver Options: Users can also override logging driver options for containers using the --log-opt flag with docker run.

Example: Overrides the max-size option for a container.
Customized Logging Configuration: Allows tailoring logging configurations to the specific needs of individual containers.

Summary: The lesson covers setting the system-wide default logging driver, overriding it for containers, and customizing logging configurations for specific container requirements.

```bash

docker info | grep Logging
# no swap

sudo vi /ect/docker/daemon.json
{
    "log-driver": "json-file", // syslog,  
    "log-opts": {
        "max-size": "15m"
    }
}
#exit vi

#restart docker
sudo systemctl restart docker
docker info


# ////

docker run --log-driver syslog nginx
# runs with the syslog log driver
# ctrl + c -- to stop it

docker run --log-driver json-file --log-opt max-size=50m nginx
# change the max-size of the log file

```

[docker logging](https://docs.docker.com/config/containers/logging/configure/)


* **Introduction to Docker Swarm**: This lesson introduces Docker Swarm and its purpose.
* **Cluster Setup**: The instructor will guide viewers on setting up a Docker Swarm cluster in upcoming lessons.
* **Distributed Cluster**: Docker Swarm enables the creation of distributed clusters of Docker machines for container management.
* **Useful Features**: Docker Swarm offers features like orchestration, high availability, and scaling.
* **Course Focus**: The course will delve deeper into implementing these features in subsequent lessons.
* **Preparation**: Viewers are encouraged to set up a Docker Swarm cluster in the Linux Academy cloud playground.
* **Cluster Configuration**: Specifies a 3-node cluster with 1 manager and 2 worker nodes.
* **Server Requirements**: Requires using Ubuntu 18.04 Bionic Beaver LTS, with a medium size for the manager and small sizes for the workers.
* **Resource Management**: Suggests deleting unnecessary servers from the playground to ensure adequate resources.
* **Follow Along**: Encourages viewers planning to follow along to set up their servers in the playground.

# Docker Swarm
Docker includes a feature called swarm
mode, which allows you to build a
distributed cluster of docker machines to
run your containers.

Docker swarm provides many useful
features, and can help facilitate
orchestration, high-availability, and scaling.
Let's build a swarm!
Provision some servers:

1. Manager
* Image: Ubuntu 18.04 Bionic Beaver LTS
* Size: Medium

2. Workers
* Image: Ubuntu 18.04 Bionic Beaver LTS
* Size: Small


# Configuring a Swarm Manager

* **Configuring Docker Swarm Manager**:
  * Introduction to the lesson about configuring a Docker Swarm manager.
  * Explanation of the role of a swarm manager in controlling and managing the cluster.
  * Overview of the upcoming setup with a swarm manager and worker nodes.
* **Steps to Configure Swarm Manager**:
  * Two main steps: Installing Docker CE and initializing a new swarm cluster.
  * Details of the Docker CE installation process.
  * Adding the user to the Docker group for command execution.
* **Initializing Swarm Cluster**:
  * Explanation that initializing the cluster on a server automatically makes it the swarm manager.
  * Demonstration of initializing the cluster using "docker swarm init."
  * Importance of specifying the "--advertise-address" with the private IP address in Linux Academy cloud playground.
* **Confirmation of Swarm Configuration**:
  * Verification of swarm status using "docker info."
  * Checking the list of nodes in the swarm using "docker node ls."
  * Confirmation that the swarm manager is active and ready.
* **Next Steps**:
  * Teaser for the next lesson, which will cover setting up swarm worker nodes.


```bash
sudo apt-get update
sudo apt-get -y install \
apt-transport-https \
ca-certificates \
curl \
gnupg-agent \
software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo apt-key fingerprint 0EBFCD88
sudo add-apt-repository \
"deb [arch=amd64] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) \
stable"
sudo apt-get update
sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic conta
sudo usermod -a -G docker cloud_user

docker swarm init --advertise-addr <swarm manager private IP>

docker info

docker node ls

```

# configuring swarm nodes (worker nodes)


* **Configuring Swarm Nodes**:
  * Introduction to the lesson about configuring swarm nodes.
  * Explanation of the roles of swarm manager and worker nodes.
  * Clarification that worker nodes perform the actual work.
* **Steps to Configure Swarm Nodes**:
  * Installation of Docker CE on worker nodes.
  * Demonstration of the installation process on two worker nodes in parallel.
  * Addition of "cloud_user" to the docker group and logging out and in for changes to take effect.
* **Joining Worker Nodes to the Swarm**:
  * Generation of a join command with a join token on the swarm manager using "docker swarm join-token worker."
  * Copying and pasting the generated join command to worker nodes for joining the cluster.
* **Confirmation of Swarm Configuration**:
  * Verification of swarm status on worker nodes using "docker info."
  * Observation that worker nodes have joined as workers.
  * Viewing swarm information on the manager node.
  * Checking the list of swarm nodes using "docker node ls."
* **Summary and Future Topics**:
  * Successful initialization of a 3-node cluster with 1 manager and 2 worker nodes.
  * Teaser for the next lesson on backup and restoration with Docker swarm.
  * Mention of upcoming sections focusing on the practical use of Docker swarm.



```bash

sudo apt-get update
sudo apt-get -y install \
apt-transport-https \
ca-certificates \
curl \
gnupg-agent \
software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo apt-key fingerprint 0EBFCD88
sudo add-apt-repository \
"deb [arch=amd64] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) \
stable"
sudo apt-get update
sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic conta
sudo usermod -a -G docker cloud_user

docker swarm join-token worker

docker swarm join --token <token> <swarm manager private IP>:2377

docker node ls

```



# back and restore with docker swarm

* **Backup and Restore for Docker Swarm**:
  * Overview of the lesson on backing up and restoring Docker swarm.
  * Introduction to the process on a swarm manager.
* **Backup Procedure**:
  * Stopping the Docker service temporarily for backup purposes.
  * Using `sudo tar` to create a backup archive (`backup.tar.gz`) of the `/var/lib/docker/swarm` directory.
  * Restarting Docker service after completing the backup.
  * Mention of automating backups through shell scripts or cron jobs.
* **Restoration Procedure**:
  * Clearing the contents of `/var/lib/docker/swarm` to ensure a clean directory.
  * Extracting the backup contents from `backup.tar.gz` into `/var/lib/docker/swarm`.
  * Restarting the Docker service.
  * Checking the status with `docker node ls` to confirm successful restoration.
* **Summary**:
  * Emphasis on the simplicity of backup and restoration for Docker swarm by managing the data in `/var/lib/docker/swarm` directory.
  * Conclusion of the lesson.


```bash
sudo systemctl stop docker
# stops docker

sudo tar -zvcf backup.tar.gz /var/lib/docker/swarm
# tar/zip up everythihng
ls
# check for the tar.gz

sudo systemctl start docker
# restart the docker

## -- restore

sudo systsemctl stop docker
sudo rm -rf /var/lib/docker/swarm/*
sudo tar -zxvf backup.tar.gz -C /var/lib/docker/swarm/
sudo systsemctl start docker
docker node ls


```

# Namespaces and Control Groups in Docker

* **Namespaces and Control Groups in Docker**:
  * Explanation of key concepts for the Docker Certified Associate Exam.
* **Namespaces**:
  * Overview of how namespaces isolate processes from resources.
  * Mention that namespaces limit resource visibility and usage in a transparent manner.
  * Docker's use of namespaces for container isolation.
  * List of some Docker namespaces and their purposes: pid, net, ipc, mnt, and uts.
  * Special configuration required for the user namespace, allowing a container process to run as root while mapped to an unprivileged user on the host.
* **Control Groups (cgroups)**:
  * Explanation that cgroups limit resource usage rather than visibility.
  * Docker's use of cgroups to enforce resource usage rules.
* **Exam Preparation**:
  * General understanding of namespaces and cgroups and their roles in Docker.
  * Awareness of common Docker namespaces and the unique nature of the user namespace.
* **Conclusion**:
  * End of the lesson and preparation for the next one.


# Namespaces
Namespaces are a Linux technology that
allows processes to be isolated in terms of
the resources that they see. They can be
used to prevent different processes from
interfering or interacting with one another.

Docker uses namespaces to isolate
containers. This technology allows
containers to operate independently and
securely.

Docker uses namespaces such as the
following to isolate resources for
containers:

* pid: Process isolation
* net: Network interfaces
* ipc: Inter-process communication 
* mnt: Filesystem mounts
* uts: Kernel and version identifiers
* user namespaces: Requires special configuration. Allows container processes to run as root inside the container while mapping that user to an unprivileged user on the host.






Installing and Configuring the Docker Engine
============================================

Introduction
------------

Docker CE is a great way to get started using the Docker engine. It is free and open-source, but provides a high-quality container runtime. This lab will help you practice the steps involved in installing and configuring the Docker Engine. You will practice installing Docker CE and configuring a logging driver. This lab will help provide you with some basic insight into how the Docker Engine is installed and configured on systems in the real world.

### Instructions

Your company is ready to start using Docker on some of their servers. In order to get started, they want you to set up and configure Docker CE on a server that has already been set up. You will need to make sure that the server meets the following specifications:

*   Docker CE is installed and running on the server.
*   Use the latest Docker CE version.
*   The user `cloud_user` has permission to run Docker commands.
*   The default logging driver is set to `syslog`.

If you get stuck, feel free to check out the solution video, or the detailed instructions under each objective. Good luck!

**Note:** _When copying and pasting code into Vim from the lab guide, first enter `:set paste` (and then `i` to enter insert mode) to avoid adding unnecessary spaces and hashes. To save and quit the file, press_ **Escape** _followed by `:wq`. To exit the file_ **without** _saving, press_ **Escape** _followed by `:q!`._

Solution
--------

Log in to the server using the credentials provided:

`ssh cloud_user@<PUBLIC_IP_ADDRESS>`
ssh cloud_user@34.200.253.41
34.200.253.41
OsVGwp6(


### Install Docker CE on the Server

1.  First, make sure old versions of Docker are not present on the system:
    
    `sudo apt-get remove docker docker-engine docker.io containerd runc`
    
2.  Then, update the apt package index:
    
    `sudo apt update -y`
    
3.  Install the packages needed for apt to use a repository over HTTPS:
    
    `sudo apt install -y ca-certificates curl gnupg`
    
4.  Add the official Docker GPG key:
    
```
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
```

    
5.  Change the `docker.gpg` file permissions:
    
    `sudo chmod a+r /etc/apt/keyrings/docker.gpg`
    
6.  Set up the repository:
    
    `
echo \
"deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
"$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
    `
    
7.  Update the list of available packages:
    
    `sudo apt -y update`
    
8.  Install Docker packages:
    
    `sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin`
    
    > **Note:** The package installation may take a few minutes.
    
9.  Verify that your installation is working:
    
    `sudo docker run hello-world`
    

### Give `cloud_user` Access to Run Docker Commands

1.  Make sure the `docker` group was created:
    
    `sudo groupadd docker`
    
2.  Add your user to the `docker` group:
    
    `sudo usermod -aG docker $USER`
    
3.  Either log out and back in as the `cloud_user`, or run the following command:
    
    `newgrp docker`
    
4.  Once you are logged back in, or have executed the mentioned command, verify the access for the `cloud_user`:
    
    `docker run hello-world`
    

### Set the Default Logging Driver to `syslog`

1.  Edit `daemon.json`:
    
    `sudo vi /etc/docker/daemon.json`
    
2.  Add configuration to `daemon.json` to set the default logging driver:
    
    `{ "log-driver": "syslog" }`
    
3.  Restart Docker:
    
    `sudo systemctl restart docker`
    
4.  Verify that the logging driver was set properly:
    
    `docker info | grep Logging`
    
5.  This command should return a line that says:
    
    `Logging Driver: syslog`
    
6.  Configure Docker to start on boot:
    
    `sudo systemctl enable docker.service`
    
7.  Configure the containerd service to start on boot:
    
    `sudo systemctl enable containerd.service`
    

Conclusion
----------

Congratulations, you've completed this hands-on lab!


------------------------------------------------------------------------

Building a Docker Swarm
=======================

Introduction
------------

Docker swarm allows you to quickly move beyond simply using Docker to run containers. With swarm, you can easily set up a cluster of Docker servers capable of providing useful orchestration features. This lab will allow you to become familiar with the process of setting up a simple swarm cluster on a set of servers. You will configure a swarm master and two worker nodes, forming a working swarm cluster.

### Instructions

Your company is ready to move forward with using Docker to run their applications. However, they have some complex container apps that can take advantage of the cluster management and orchestration features of Docker swarm. You have been asked to stand up a simple Docker swarm cluster to be used for some initial testing. A set of servers has already been provisioned for this purpose. The swarm cluster should meet the following criteria:

*   One Swarm manager.
*   Two worker nodes.
*   All nodes should use Docker CE version `5:18.09.5~3-0~ubuntu-bionic`.
*   Both worker nodes should be joined to the cluster.
*   `cloud_user` should be able to run docker commands on all three servers.

If you get stuck, feel free to check out the solution video, or the detailed instructions under each objective. Good luck!

Solution
--------

Begin by logging in to the lab server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

# Swarm Manager
ssh cloud_user@3.236.177.66
Y*Y4L#cg

# Swarm worker1
ssh cloud_user@44.193.229.119
Y*Y4L#cg

# Swarm worker2
ssh cloud_user@34.201.8.158
Y*Y4L#cg



### Install Docker CE on all three nodes

1.  On all three servers, install Docker CE.

`sudo apt-get update`

`
sudo apt-get -y install apt-transport-https ca-certificates 
curl gnupg-agent software-properties-common
`

`curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -`

`
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
`

`sudo apt-get update`

`sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic containerd.io`

1.  Add cloud\_user to the Docker group so that you can run docker commands as cloud\_user.

`sudo usermod -a -G docker cloud_user`

Log out each server, then log back in.

1.  You can verify the installation on each server like so:

`docker version`

### Configure the swarm manager

1.  On the swarm manager server, initialize the swarm. Be sure to replace `<swarm manager private IP>` in this command with the actual Private IP of the swarm manager (NOT the public IP).

`docker swarm init --advertise-addr <swarm manager private IP>`
docker swarm init --advertise-addr 3.236.177.66

### Join the worker nodes to the cluster

1.  On the swarm manager, get a join command with a token:

`docker swarm join-token worker`

This should provide a command that begins `docker swarm join ...`. Copy that command and run it on both worker servers.

1.  Go back to the swarm manager and list the nodes.

`docker node ls`

Verify that you can see all three servers listed (including the manager). All three should have a status of `READY`. Once all three servers are ready, you have built your own Docker swarm cluster!

Conclusion
----------

Congratulations, you've completed this hands-on lab!


