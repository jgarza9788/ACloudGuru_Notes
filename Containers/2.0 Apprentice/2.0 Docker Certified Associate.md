

**Exam Details:**

*   **Exam Title:** Docker Certified Associate
*   **Exam Code:** DCA
*   **Exam Duration:** 90 minutes
*   **Number of Questions:** Approximately 55-60 multiple-choice questions
*   **Passing Score:** 70%
*   **Exam Cost:** The cost may vary depending on your location and the testing center.

**Topics Covered:** The Docker Certified Associate exam covers a wide range of topics related to Docker and containerization. These topics include:

1.  **Docker Fundamentals:**
    
    *   Understanding containerization concepts.
    *   Docker architecture, components, and services.
    *   Basic Docker commands and operations.
2.  **Docker Installation and Configuration:**
    
    *   Installing and configuring Docker on various platforms.
    *   Managing Docker configurations and settings.
3.  **Container Management:**
    
    *   Creating, running, and managing Docker containers.
    *   Working with container images and Docker Hub.
4.  **Docker Networking:**
    
    *   Configuring and managing Docker networking.
    *   Understanding container communication and connectivity.
5.  **Docker Storage and Volumes:**
    
    *   Managing data persistence with Docker volumes.
    *   Understanding storage drivers and options.
6.  **Docker Compose:**
    
    *   Defining and managing multi-container applications using Docker Compose.
    *   Compose file structure and syntax.
7.  **Docker Security:**
    
    *   Securing Docker containers and images.
    *   Implementing security best practices.
    *   User authentication and authorization.
8.  **Docker Orchestration:**
    
    *   Introduction to Docker Swarm and Kubernetes.
    *   Deploying and managing containerized applications in an orchestrated environment.
9.  **Docker Logging and Monitoring:**
    
    *   Collecting and analyzing container logs.
    *   Implementing monitoring and alerting solutions.
10.  **Troubleshooting and Maintenance:**
    
    *   Diagnosing and troubleshooting common Docker issues.
    *   Performing regular maintenance tasks.

**Preparation:** To prepare for the Docker Certified Associate exam, consider the following steps:

1.  **Study the Official Documentation:** Review the Docker documentation thoroughly as it covers all the essential topics.
    
2.  **Hands-On Experience:** Gain practical experience by working with Docker containers and images.
    
3.  **Training Courses:** Consider taking Docker training courses or online tutorials.
    
4.  **Practice Exams:** Use practice exams and sample questions to assess your readiness.
    
5.  **Study Guides:** Explore study guides and books related to Docker certification.
    
6.  **Docker Playground:** Utilize Docker playgrounds or sandboxes to experiment with Docker in a risk-free environment.
    
7.  **Join the Community:** Participate in Docker communities and forums to ask questions and learn from others.
    

**Conclusion:** The Docker Certified Associate certification demonstrates your proficiency in Docker containerization technology. It's a valuable credential for professionals involved in container-based application development, deployment, and management. Prepare thoroughly, gain hands-on experience, and you'll be well-equipped to pass the DCA exam and further your career in containerization and DevOps.


---

# Course Features and Tools.txt

* Cloud Playground: Accessible through the "Playground" button, allows you to spin up cloud servers for hands-on learning.
* Hands-On Labs: Offers self-contained environments with temporary servers and step-by-step instructions.
* Course Scheduler: Helps create a study schedule for the course content.
* Flash Cards: Useful for memorization, especially important for the text-based multiple-choice Docker Certified Associate exam.
* Practice Exam: A multiple-choice exam similar to the Docker Certified Associate exam for preparation.
* Community Tab: Offers ways to connect with instructors and other students, ask questions, and provide assistance during the course.

---

# Docker Editions

* Docker Editions: Docker offers two editions, Community Edition (CE) and Enterprise Edition (EE).
* Docker CE: The free and open-source version of Docker Engine.
* Core Functionality: Docker CE provides core container functionality, including running containers, Docker Swarm, networking, and security.
* Feature Parity: Docker CE and EE have the same core features and receive updates on the same schedule.
* Emphasis: This section focuses on Docker Community Edition, covering installation, configuration, Docker Swarm, and basic Docker functionality.

---



* Docker CE Installation: This lesson demonstrates the installation of Docker Community Edition (CE) on a CentOS server.
* Server Setup: A CentOS 7 server is created in the cloud playground for installation.
* Required Packages: Device-mapper-persistent-data and lvm2 packages are installed as prerequisites.
* Adding Docker Repo: Docker CE repository is added using the yum-config-manager command.
* Docker Installation: Docker CE is installed with a specific version (18.09.5), along with docker-ce-cli and containerd.io.
* Docker Service Management: The Docker service is started and enabled using systemctl to ensure it runs on server startup.
* User Permissions: The cloud_user is added to the docker group to grant Docker command access.
* Testing Docker: Docker is verified by running a simple docker run command to execute a container.
* Successful Installation: The container runs successfully, confirming the Docker installation on CentOS.
* Next Steps: The lesson concludes with a preview of installing Docker CE on an Ubuntu environment in the next lesson.


# Installing Docker CE (CentOS)

To Install Docker CE on CentOS, we will
need to do the following:

* Provision a Server
    * Image: CentOS 7
    * Size: Small
* Install Required Packages: Install some
required packages (yum-utils, device-
mapper-persistent-data, and lvm2).
* Add the Docker Repo
* Install Docker and Containerd packages
* Start and Enable the Docker Service
* Configure cloud_user to be Able to Use
Docker: Add cloud user to the docker
group, then log out and back in.
* Run a Container to Test the
Installation: Test the installation by
running the hello-world image.

# Installing Docker CE (Ubuntu)

To Install Docker CE on Ubuntu, we will
need to do the following:

* Provision a Server
    * Image: Ubuntu 18.04 Bionic Beaver LTS
Size: Small
* Install Required Packages
* Add the Docker GPG Key and Repo
* Install Docker and Containerd packages
* Configure cloud_user to be Able to Use
Docker: Add cloud user to the docker
group, then log out and back in.
* Run a Container to Test the
Installation: Test the installation by
running the hello-world image.

---

# Selecting a Storage Driver

Storage drivers provide a pluggable
framework for managing the temporary,
internal storage of a container's writable
layer.
Docker supports a variety of storage
drivers. The best storage driver to use
depends on your environment and your
storage needs.
overlay2: File-based storage. Default for
Ubuntu and CentOS 8+.
devicemapper: Block storage, more
efficient for doing lots of writes. Default for
CentOS 7 and earlier.
You can find out what storage driver is
currently configured with docker info

# Selecting a Storage Driver

Docker automatically selects a default
storage driver that is compatible with your
environment.
However, in some cases you may want to
override the default to use a different
driver.
There are two ways to do this:
* Set the --storage-driver flag when
starting Docker (in your system unit file
for example).
"storage-driver" value in
* Set the
/etc/docker/daemon.json.

```bash

docker info
# shows the storage driver

# edit this file 
sudo vi /user/lib/systemd/system/docker.service
# change the storage driver
# in vi
--storage-driver devicemapper
# exit vi

# reload docker
sudo systemctl daemon-reload
sudo systemctl restart docker
docker info

# ^ undo this change above

# /////////////////////////////////

sudo vi /etc/docker/daemon.json
# in vi
{
    "system-driver": "devicemapper"
}
#exit vi

# reload docker
sudo systemctl daemon-reload
sudo systemctl restart docker
docker info

```

# running Containers

* Running Containers: This lesson focuses on running containers using the docker run command.
* Docker Run Basics: The basic structure of the docker run command is introduced, emphasizing the required elements: docker, run, and a reference to an image.
* Image Tags: Images can have tags, representing versions or variants. Without specifying a tag, Docker automatically chooses the latest version.
* Running Specific Commands: Demonstrates running containers with specific commands and arguments, allowing customization of container behavior.
* Detached Mode (-d): Explains the -d flag, used to run containers in detached mode, allowing them to run in the background and releasing the command prompt.
* Naming Containers (--name): Shows how to assign custom names to containers using the --name flag, making it easier to manage and reference them.
* Container Restart Policies (--restart): Discusses different restart policies (no, on-failure, always, unless-stopped) for controlling container restart behavior in various scenarios.
* Port Mapping (-p): Demonstrates using the -p flag to publish container ports, making them accessible from the host system or the network.
* Automatic Container Removal (--rm): Explains the --rm flag, which automatically deletes containers upon stopping, preventing lingering containers from taking up disk space.
* Memory Limits (--memory and --memory-reservation): Covers setting memory limits for containers using --memory and --memory-reservation flags.
* Listing Containers (docker ps and docker ps -a): Shows how to list currently running containers with docker ps and all containers (including stopped ones) with docker ps -a.
* Stopping and Starting Containers (docker container stop and docker container start): Illustrates stopping and starting containers using docker container stop and docker container start.
* Deleting Containers (docker container rm): Explains how to delete containers with docker container rm, ensuring that containers are first stopped if necessary.
* Managing Containers: Summarizes key container management commands and concepts learned in the lesson.


```bash

docker run hello-world
# runs a container in docker

docker run nginx:1.15.11
# runs nginx with tag

docker run busybox echo hello-world!
# starts a busybox with an hello-world command

docker run -d nginx 
# -d detatched mode (runs in background)
docker ps

docker container stop <id>


docker run -d --name nginx --restart always nginx 
# restart in an endless loop

docker run -d --name nginx --restart unless-stopped -p 8080:80 nginx 
# -p publish the port
# 8080 <- host part on the server
# 80 <- port for inside the container

# --rm : remove the container when done

#--memory 500M 
# memory limit

#--memory-reservation 256M
# memory reservation (should be less then the memory limit, if server is under a lot of load)

```


# Running a Container
Some commonly-used options:
* -d: Run container in detached mode.
The docker run command will exit
immediately and the container will run
in the background.

* --name: A container is assigned a
random name by default, but you can
give it a more descriptive name with this
flag.

* --restart: Specify when the container
should be automatically restarted.
    * no (default): Never restart the container.
    * on-failure: Only if the container fails (exits with a non-zero exit code).
    * always: Always restart the container whether it succeeds or fails. Also starts the container automatically on daemon startup.
    * unless-stopped: Always restart the container whether it succeeds or fails, and on daemon startup, unless the container was manually stopped.


[docker run documentation](https://docs.docker.com/engine/reference/run/)


```bash
docker ps
# list all active containers

curl localhost:8080

docker ps -a
# shows all the containers, even past containers

docker container stop <name or id>
docker container start <name of id>
docker container rm <name of id>
# stop the container before remove



```

## Upgrading Docker Engine: 
This lesson covers the process of upgrading the Docker Engine.
Initial State: The instructor is currently using Docker Community Edition version 18.09.5 on an Ubuntu Server.

## Downgrading: 
The instructor explains that they will first demonstrate downgrading Docker before proceeding with the upgrade.

## Steps to Downgrade:
Stop Docker: sudo systemctl stop docker.

## Remove Docker packages: 
sudo apt-get remove docker-ce docker-ce-cli.
Install an earlier version (downgrade): sudo apt-get install -y docker-ce=18.09.4 docker-ce-cli=18.09.4.

## Upgrading Docker: 
The instructor shows that upgrading Docker is simpler and does not require stopping Docker or removing packages.

## Steps to Upgrade:
Install the new version: sudo apt-get install -y docker-ce=18.09.5 docker-ce-cli=18.09.5.

## Confirmation: 
The instructor verifies the Docker version using the docker version command.

## Summary: 
The lesson demonstrates both the downgrade and upgrade processes for Docker, emphasizing that upgrading involves installing a newer version of Docker packages.


```bash

sudo systemctl stop docker

sudo apt-get remove -y docker-ce docker-ce-cli

sudo apt-get update

sudo apt-get install -y docker-ce=5:18.09.4~3-0~ubuntu-bionic docker-ce-cli=5:18.09.4~3-0~ubuntu-bionic

docker version

```


# Configuring Logging Drivers
Logging drivers are a pluggable framework
for accessing log data from services and
containers in Docker. Docker supports a
variety of logging drivers.

Configure the default logging driver by
setting log-driver and log-opts
in
/etc/docker/daemon.json

You override the default logging driver and
options for a container with the --log-driver
and --log-opt flags when using docker run.


Logging Drivers in Docker: 
This lesson covers the concept of logging drivers in Docker, which allows customization of log data handling for containers and services.

Variety of Logging Drivers: 
Docker supports various logging drivers, and users can choose from them based on their needs.

Default Logging Driver: 
Docker has a system-wide default logging driver, which can be overridden for individual containers.

No Need to Configure Default: 
Docker has a built-in logging driver configuration, so users don't need to configure it if the default is acceptable.

Setting Default Logging Driver: 
To set the default logging driver, edit the daemon.json file (usually located at /etc/docker/daemon.json) and specify the desired logging driver using the log-driver key.

Additional Logging Driver Configuration: 
Users can also configure additional options for logging drivers using the log-opts key.

Example: Demonstrates setting the default logging driver to json-file with a max size of 15 megabytes.

Restart Docker: After editing the daemon.json file, restart Docker for changes to take effect.

Overriding Logging Driver for Containers: Users can override the default logging driver for individual containers using the --log-driver flag with docker run.

Example: Runs an Nginx container with the syslog logging driver.
Overriding Logging Driver Options: Users can also override logging driver options for containers using the --log-opt flag with docker run.

Example: Overrides the max-size option for a container.
Customized Logging Configuration: Allows tailoring logging configurations to the specific needs of individual containers.

Summary: The lesson covers setting the system-wide default logging driver, overriding it for containers, and customizing logging configurations for specific container requirements.

```bash

docker info | grep Logging
# no swap

sudo vi /ect/docker/daemon.json
{
    "log-driver": "json-file", // syslog,  
    "log-opts": {
        "max-size": "15m"
    }
}
#exit vi

#restart docker
sudo systemctl restart docker
docker info


# ////

docker run --log-driver syslog nginx
# runs with the syslog log driver
# ctrl + c -- to stop it

docker run --log-driver json-file --log-opt max-size=50m nginx
# change the max-size of the log file

```

[docker logging](https://docs.docker.com/config/containers/logging/configure/)


* **Introduction to Docker Swarm**: This lesson introduces Docker Swarm and its purpose.
* **Cluster Setup**: The instructor will guide viewers on setting up a Docker Swarm cluster in upcoming lessons.
* **Distributed Cluster**: Docker Swarm enables the creation of distributed clusters of Docker machines for container management.
* **Useful Features**: Docker Swarm offers features like orchestration, high availability, and scaling.
* **Course Focus**: The course will delve deeper into implementing these features in subsequent lessons.
* **Preparation**: Viewers are encouraged to set up a Docker Swarm cluster in the Linux Academy cloud playground.
* **Cluster Configuration**: Specifies a 3-node cluster with 1 manager and 2 worker nodes.
* **Server Requirements**: Requires using Ubuntu 18.04 Bionic Beaver LTS, with a medium size for the manager and small sizes for the workers.
* **Resource Management**: Suggests deleting unnecessary servers from the playground to ensure adequate resources.
* **Follow Along**: Encourages viewers planning to follow along to set up their servers in the playground.

# Docker Swarm
Docker includes a feature called swarm
mode, which allows you to build a
distributed cluster of docker machines to
run your containers.

Docker swarm provides many useful
features, and can help facilitate
orchestration, high-availability, and scaling.
Let's build a swarm!
Provision some servers:

1. Manager
* Image: Ubuntu 18.04 Bionic Beaver LTS
* Size: Medium

2. Workers
* Image: Ubuntu 18.04 Bionic Beaver LTS
* Size: Small


# Configuring a Swarm Manager

* **Configuring Docker Swarm Manager**:
  * Introduction to the lesson about configuring a Docker Swarm manager.
  * Explanation of the role of a swarm manager in controlling and managing the cluster.
  * Overview of the upcoming setup with a swarm manager and worker nodes.
* **Steps to Configure Swarm Manager**:
  * Two main steps: Installing Docker CE and initializing a new swarm cluster.
  * Details of the Docker CE installation process.
  * Adding the user to the Docker group for command execution.
* **Initializing Swarm Cluster**:
  * Explanation that initializing the cluster on a server automatically makes it the swarm manager.
  * Demonstration of initializing the cluster using "docker swarm init."
  * Importance of specifying the "--advertise-address" with the private IP address in Linux Academy cloud playground.
* **Confirmation of Swarm Configuration**:
  * Verification of swarm status using "docker info."
  * Checking the list of nodes in the swarm using "docker node ls."
  * Confirmation that the swarm manager is active and ready.
* **Next Steps**:
  * Teaser for the next lesson, which will cover setting up swarm worker nodes.


```bash
sudo apt-get update
sudo apt-get -y install \
apt-transport-https \
ca-certificates \
curl \
gnupg-agent \
software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo apt-key fingerprint 0EBFCD88
sudo add-apt-repository \
"deb [arch=amd64] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) \
stable"
sudo apt-get update
sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic conta
sudo usermod -a -G docker cloud_user

docker swarm init --advertise-addr <swarm manager private IP>

docker info

docker node ls

```

# configuring swarm nodes (worker nodes)


* **Configuring Swarm Nodes**:
  * Introduction to the lesson about configuring swarm nodes.
  * Explanation of the roles of swarm manager and worker nodes.
  * Clarification that worker nodes perform the actual work.
* **Steps to Configure Swarm Nodes**:
  * Installation of Docker CE on worker nodes.
  * Demonstration of the installation process on two worker nodes in parallel.
  * Addition of "cloud_user" to the docker group and logging out and in for changes to take effect.
* **Joining Worker Nodes to the Swarm**:
  * Generation of a join command with a join token on the swarm manager using "docker swarm join-token worker."
  * Copying and pasting the generated join command to worker nodes for joining the cluster.
* **Confirmation of Swarm Configuration**:
  * Verification of swarm status on worker nodes using "docker info."
  * Observation that worker nodes have joined as workers.
  * Viewing swarm information on the manager node.
  * Checking the list of swarm nodes using "docker node ls."
* **Summary and Future Topics**:
  * Successful initialization of a 3-node cluster with 1 manager and 2 worker nodes.
  * Teaser for the next lesson on backup and restoration with Docker swarm.
  * Mention of upcoming sections focusing on the practical use of Docker swarm.



```bash

sudo apt-get update
sudo apt-get -y install \
apt-transport-https \
ca-certificates \
curl \
gnupg-agent \
software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo apt-key fingerprint 0EBFCD88
sudo add-apt-repository \
"deb [arch=amd64] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) \
stable"
sudo apt-get update
sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic conta
sudo usermod -a -G docker cloud_user

docker swarm join-token worker

docker swarm join --token <token> <swarm manager private IP>:2377

docker node ls

```



# back and restore with docker swarm

* **Backup and Restore for Docker Swarm**:
  * Overview of the lesson on backing up and restoring Docker swarm.
  * Introduction to the process on a swarm manager.
* **Backup Procedure**:
  * Stopping the Docker service temporarily for backup purposes.
  * Using `sudo tar` to create a backup archive (`backup.tar.gz`) of the `/var/lib/docker/swarm` directory.
  * Restarting Docker service after completing the backup.
  * Mention of automating backups through shell scripts or cron jobs.
* **Restoration Procedure**:
  * Clearing the contents of `/var/lib/docker/swarm` to ensure a clean directory.
  * Extracting the backup contents from `backup.tar.gz` into `/var/lib/docker/swarm`.
  * Restarting the Docker service.
  * Checking the status with `docker node ls` to confirm successful restoration.
* **Summary**:
  * Emphasis on the simplicity of backup and restoration for Docker swarm by managing the data in `/var/lib/docker/swarm` directory.
  * Conclusion of the lesson.


```bash
sudo systemctl stop docker
# stops docker

sudo tar -zvcf backup.tar.gz /var/lib/docker/swarm
# tar/zip up everythihng
ls
# check for the tar.gz

sudo systemctl start docker
# restart the docker

## -- restore

sudo systsemctl stop docker
sudo rm -rf /var/lib/docker/swarm/*
sudo tar -zxvf backup.tar.gz -C /var/lib/docker/swarm/
sudo systsemctl start docker
docker node ls


```

# Namespaces and Control Groups in Docker

* **Namespaces and Control Groups in Docker**:
  * Explanation of key concepts for the Docker Certified Associate Exam.
* **Namespaces**:
  * Overview of how namespaces isolate processes from resources.
  * Mention that namespaces limit resource visibility and usage in a transparent manner.
  * Docker's use of namespaces for container isolation.
  * List of some Docker namespaces and their purposes: pid, net, ipc, mnt, and uts.
  * Special configuration required for the user namespace, allowing a container process to run as root while mapped to an unprivileged user on the host.
* **Control Groups (cgroups)**:
  * Explanation that cgroups limit resource usage rather than visibility.
  * Docker's use of cgroups to enforce resource usage rules.
* **Exam Preparation**:
  * General understanding of namespaces and cgroups and their roles in Docker.
  * Awareness of common Docker namespaces and the unique nature of the user namespace.
* **Conclusion**:
  * End of the lesson and preparation for the next one.


# Namespaces
Namespaces are a Linux technology that
allows processes to be isolated in terms of
the resources that they see. They can be
used to prevent different processes from
interfering or interacting with one another.

Docker uses namespaces to isolate
containers. This technology allows
containers to operate independently and
securely.

Docker uses namespaces such as the
following to isolate resources for
containers:

* pid: Process isolation
* net: Network interfaces
* ipc: Inter-process communication 
* mnt: Filesystem mounts
* uts: Kernel and version identifiers
* user namespaces: Requires special configuration. Allows container processes to run as root inside the container while mapping that user to an unprivileged user on the host.






Installing and Configuring the Docker Engine
============================================

Introduction
------------

Docker CE is a great way to get started using the Docker engine. It is free and open-source, but provides a high-quality container runtime. This lab will help you practice the steps involved in installing and configuring the Docker Engine. You will practice installing Docker CE and configuring a logging driver. This lab will help provide you with some basic insight into how the Docker Engine is installed and configured on systems in the real world.

### Instructions

Your company is ready to start using Docker on some of their servers. In order to get started, they want you to set up and configure Docker CE on a server that has already been set up. You will need to make sure that the server meets the following specifications:

*   Docker CE is installed and running on the server.
*   Use the latest Docker CE version.
*   The user `cloud_user` has permission to run Docker commands.
*   The default logging driver is set to `syslog`.

If you get stuck, feel free to check out the solution video, or the detailed instructions under each objective. Good luck!

**Note:** _When copying and pasting code into Vim from the lab guide, first enter `:set paste` (and then `i` to enter insert mode) to avoid adding unnecessary spaces and hashes. To save and quit the file, press_ **Escape** _followed by `:wq`. To exit the file_ **without** _saving, press_ **Escape** _followed by `:q!`._

Solution
--------

Log in to the server using the credentials provided:

`ssh cloud_user@<PUBLIC_IP_ADDRESS>`
ssh cloud_user@34.200.253.41
34.200.253.41
OsVGwp6(


### Install Docker CE on the Server

1.  First, make sure old versions of Docker are not present on the system:
    
    `sudo apt-get remove docker docker-engine docker.io containerd runc`
    
2.  Then, update the apt package index:
    
    `sudo apt update -y`
    
3.  Install the packages needed for apt to use a repository over HTTPS:
    
    `sudo apt install -y ca-certificates curl gnupg`
    
4.  Add the official Docker GPG key:
    
```
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
```

    
5.  Change the `docker.gpg` file permissions:
    
    `sudo chmod a+r /etc/apt/keyrings/docker.gpg`
    
6.  Set up the repository:
    
    `
echo \
"deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
"$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
    `
    
7.  Update the list of available packages:
    
    `sudo apt -y update`
    
8.  Install Docker packages:
    
    `sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin`
    
    > **Note:** The package installation may take a few minutes.
    
9.  Verify that your installation is working:
    
    `sudo docker run hello-world`
    

### Give `cloud_user` Access to Run Docker Commands

1.  Make sure the `docker` group was created:
    
    `sudo groupadd docker`
    
2.  Add your user to the `docker` group:
    
    `sudo usermod -aG docker $USER`
    
3.  Either log out and back in as the `cloud_user`, or run the following command:
    
    `newgrp docker`
    
4.  Once you are logged back in, or have executed the mentioned command, verify the access for the `cloud_user`:
    
    `docker run hello-world`
    

### Set the Default Logging Driver to `syslog`

1.  Edit `daemon.json`:
    
    `sudo vi /etc/docker/daemon.json`
    
2.  Add configuration to `daemon.json` to set the default logging driver:
    
    `{ "log-driver": "syslog" }`
    
3.  Restart Docker:
    
    `sudo systemctl restart docker`
    
4.  Verify that the logging driver was set properly:
    
    `docker info | grep Logging`
    
5.  This command should return a line that says:
    
    `Logging Driver: syslog`
    
6.  Configure Docker to start on boot:
    
    `sudo systemctl enable docker.service`
    
7.  Configure the containerd service to start on boot:
    
    `sudo systemctl enable containerd.service`
    

Conclusion
----------

Congratulations, you've completed this hands-on lab!


------------------------------------------------------------------------

Building a Docker Swarm
=======================

Introduction
------------

Docker swarm allows you to quickly move beyond simply using Docker to run containers. With swarm, you can easily set up a cluster of Docker servers capable of providing useful orchestration features. This lab will allow you to become familiar with the process of setting up a simple swarm cluster on a set of servers. You will configure a swarm master and two worker nodes, forming a working swarm cluster.

### Instructions

Your company is ready to move forward with using Docker to run their applications. However, they have some complex container apps that can take advantage of the cluster management and orchestration features of Docker swarm. You have been asked to stand up a simple Docker swarm cluster to be used for some initial testing. A set of servers has already been provisioned for this purpose. The swarm cluster should meet the following criteria:

*   One Swarm manager.
*   Two worker nodes.
*   All nodes should use Docker CE version `5:18.09.5~3-0~ubuntu-bionic`.
*   Both worker nodes should be joined to the cluster.
*   `cloud_user` should be able to run docker commands on all three servers.

If you get stuck, feel free to check out the solution video, or the detailed instructions under each objective. Good luck!

Solution
--------

Begin by logging in to the lab server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

# Swarm Manager
ssh cloud_user@3.236.177.66
Y*Y4L#cg

# Swarm worker1
ssh cloud_user@44.193.229.119
Y*Y4L#cg

# Swarm worker2
ssh cloud_user@34.201.8.158
Y*Y4L#cg



### Install Docker CE on all three nodes

1.  On all three servers, install Docker CE.

`sudo apt-get update`

`
sudo apt-get -y install apt-transport-https ca-certificates 
curl gnupg-agent software-properties-common
`

`curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -`

`
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
`

`sudo apt-get update`

`sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic containerd.io`

1.  Add cloud\_user to the Docker group so that you can run docker commands as cloud\_user.

`sudo usermod -a -G docker cloud_user`

Log out each server, then log back in.

1.  You can verify the installation on each server like so:

`docker version`

### Configure the swarm manager

1.  On the swarm manager server, initialize the swarm. Be sure to replace `<swarm manager private IP>` in this command with the actual Private IP of the swarm manager (NOT the public IP).

`docker swarm init --advertise-addr <swarm manager private IP>`
docker swarm init --advertise-addr 3.236.177.66

### Join the worker nodes to the cluster

1.  On the swarm manager, get a join command with a token:

`docker swarm join-token worker`

This should provide a command that begins `docker swarm join ...`. Copy that command and run it on both worker servers.

1.  Go back to the swarm manager and list the nodes.

`docker node ls`

Verify that you can see all three servers listed (including the manager). All three should have a status of `READY`. Once all three servers are ready, you have built your own Docker swarm cluster!

Conclusion
----------

Congratulations, you've completed this hands-on lab!


# Introduction to Docker Images

# Docker Images

Docker image is a file containing the
code and components needed to run
software in a container.

Containers and images use a layered file
system. Each layer contains only the
differences from the previous layer.

The image consists of one or more read-
only layers, while the container adds one
addition writable layer.


* Docker images are files containing all the code and components needed to run software in a container.
* Docker images consist of layers, each containing differences from the previous layer.
* Images use a layered file system to share common layers, reducing storage footprint and speeding up image transfer.
* The writeable container layer is added when a container is run and captures changes to the file system.
* Shared layers enable multiple containers to use the same base layers, optimizing resource usage.
* The layered file system makes image transfer faster and image building more efficient.
* Use the `docker image history` command to examine the layers in an image.


```md
[writable container layer] <- writeable

[web application] <- unwriteable
[python] <- unwriteable
[base ubuntu OS image] <- unwriteable
```


```bash
docker run nginx:1.15.8
# runs the container
# images are layers

docker image history <imagename>
# shows the history of the layers


```

# the components of a dockerfile

* Dockerfile is used to build Docker images, containing a set of instructions called directives.
* `FROM` directive specifies the base image.
* `ENV` directive sets environment variables for the Dockerfile.
* `RUN` directive executes a command and creates a new file system layer.
* `CMD` directive provides a default command when running a container.
* Images can be built from a Dockerfile using `docker build`.
* Docker caches layers to speed up subsequent builds if no changes occur.
* Containers can be run from the custom image using `docker run`.
* Additional image customization will be covered in the next lesson.


```bash
mkdir custom-nginx
cd custom-nginx/
vi index.html
# ~in dockerfile~
# hello world
#exit dockerfile
vi Dockerfile 
# ~in dockerfile~
#Simple ngin image
FROM ubuntu:bionic # our OS

ENV NGINX_VERSION 1.14.0-0ubuntu1.11 # variables

RUN apt-get update && apt-get install -y curl
RUN apt-get update && apt-get install -y nginx:$NGINX_VERSION

CMD ["nginx","-g","daemon off;"]

# exit dockerfile

docker build -t custom-nginx .
# build this into an image

docker fun -d -p 8080:80 custom-nginx
curl localhost:8080
# shows nginx welcome page

ls
#lists

cat index.html
#hello world!

```



# more dockerfile directives

* `EXPOSE` directive documents the ports intended to be listened on by the image.
* `WORKDIR` sets the current working directory within the container during build and runtime.
* Multiple `WORKDIR` directives can be used, either absolute or relative to the previous one.
* `COPY` and `ADD` directives move files into the container; `ADD` has additional features like downloading files from URLs or extracting archives.
* `STOPSIGNAL` specifies the signal used to terminate the container process.
* `HEALTHCHECK` allows customization of container health checks, useful for more complex health monitoring.
* Docker images can be built and tested using these directives in the Dockerfile.


```bash
mkdir custom-nginx
cd custom-nginx/
vi index.html
# ~in dockerfile~
# hello world
#exit dockerfile
vi Dockerfile 
# ~in dockerfile~
#Simple ngin image
FROM ubuntu:bionic # our OS

ENV NGINX_VERSION 1.14.0-0ubuntu1.11 # variables

RUN apt-get update && apt-get install -y curl
RUN apt-get update && apt-get install -y nginx:$NGINX_VERSION

WORKDIR /var #sets main directory when building and running
WORKDIR www #sets the child dir as a main dir
WORKDIR /etc #sets a new main directory

COPY index.html ./ #allows us to move files into this container
# this will move the file into the last WORKDIR

ADD index.html ./
# similer to copy
# but
# can copy from html
# can exstract archive

EXPOSE 80 # documents the port 

CMD ["nginx","-g","daemon off;"]

STOPSIGNAL SIGTERM 

HELATHCHECK CMD curl localhost:80 #custom health check

# exit dockerfile

docker build -t custom-nginx .
# buidl the docker image

docker run -d -p 8080:80 custom-nginx
curl localhost:8080
# get "hello world"

docker ps

docker container rm -f <container id>
```


# Building Efficient Images

* Building efficient Docker images is important for minimizing image size and resource usage.
* To build efficient images, consider the following tips:
  * Place less likely to change items on lower-level layers to benefit from caching.
  * Avoid creating unnecessary layers by bundling commands together.
  * Exclude unnecessary files, packages, or resources from the image.
* Multi-stage builds are a technique to create more efficient images by using multiple `FROM` directives in a Dockerfile.
* In multi-stage builds, each `FROM` directive starts from scratch, allowing you to copy only necessary files from previous stages.
* This technique significantly reduces the final image size, as unnecessary files and dependencies are excluded.
* Multi-stage builds are particularly useful when a build process requires additional tools or dependencies that aren't needed in the final image.


```bash

cd ~/
mkdir efficient
mkdir inefficient
cd inefficient

vi helloworld.go
##
package main
import "fmt"
func main() {
fmt.Println("hello world")
}
##

vi Dockerfile
##
FROM golang:1.12.4
WORKDIR /helloworld
COPY helloworld.go .
RUN GOOS=linux go build -a -installsuffix cgo -o helloworld .
CMD ["./helloworld"]
##

docker build -t inefficient .
docker run inefficient
docker image ls

cd ~/efficient
cp ../inefficient/helloworld.go ./
cp ../inefficient/Dockerfile ./

vi Dockerfile
FROM golang:1.12.4 AS compiler
WORKDIR /helloworld
COPY helloworld.go .
RUN GOOS=linux go build -a -installsuffix cgo -o helloworld .
FROM alpine:3.9.3
WORKDIR /root
COPY --from=compiler /helloworld/helloworld .
CMD ["./helloworld"]

docker build -t efficient .
docker run efficient
docker image ls
```

By using a multi-stage build, you ensure that only the required artifacts (the compiled executable) are included in the final image, leading to a smaller image size, reduced resource consumption, and faster image distribution. This approach is especially valuable when you have build dependencies that are not needed in the runtime environment.


# Managing Images

* `docker image pull` or `docker pull`: Downloads Docker images from Docker Hub if they don't already exist locally.
* `docker image ls` or `docker images`: Lists the Docker images on your system, and `-a` includes intermediate images.
* `docker image inspect`: Provides detailed image metadata in JSON format, with customizable output using `--format`.
* `docker image rm` or `docker rmi`: Removes Docker images, with caution when using `-f` (force) to avoid image deletion conflicts.
* Dangling Images: Images without tags or container references can become "dangling" after tag removal.
* `docker image prune`: Removes dangling images, freeing up disk space.

These are fundamental commands for Docker image management. For advanced operations, consult the official Docker documentation.

```bash

docker image ls
# lists the docker images

docker image ls -a
# all images - even the base images


docker image inspect <imagename> 
# shows details on the image

docker image inspect <imagename> --format "{{.Architechure}}"
docker image inspect <imagename> --format "{{.Architechure} {.Os}}"
# shows details on the image with custom format

docker image rm <imagename>
#delete image

docker rmi <imagename>
#delete image

docker run -d --name nginx nginx:1.14.0
docker image rm nginx:1.14.0
# fails since a container is using it

docker image rm -f nginx:1.14.0
# deletes the image anyways

docker image prune
# deletes all unused images



```


# Flattening a Docker Image to a Single Layer

* Flattening an image involves converting a multi-layered image into a single layer, typically for performance optimization.
* Docker does not officially support flattening images, but it can be done for specific use cases.
* The process involves running a container from the image, exporting the container's file system into an archive, and then importing the archive as a new image.
* Steps:
  1. Create a Dockerfile for your image.
  2. Build the image and tag it.
  3. Run a container from the image.
  4. Export the container's file system to a TAR archive using `docker export`.
  5. Import the TAR archive as a new image using `docker import`.
* The resulting image will have a single layer, but it won't necessarily save space as compared to the original image.
* Flattening images is not a common practice and should be done only when necessary for specific requirements.



```bash


cd ~/ 
mkdir alpine-hello
cd alphine-hello
vi Dockerfile

##
FROM alpine:3.9.3
RUN echo "HELLO, WORLD" > message.txt
CMD cat message.txt
##

docker build -t nonflat
docker image history nonflat

docker run -d --name flat_container nonflat
docker export flat_container > flat.tar

ls
# .tar file here


cat flat.tar | docker import - flat:latest

docker image ls

docker image history flat 
docker image history nonflat


```

# Docker registries


* Docker registries are central repositories for storing and distributing Docker images.
* Docker Hub is a public Docker registry available on the internet, where you can find and share Docker images.
* Private Docker registries offer more control and security for storing and distributing images within a private network.
* Docker provides free and open-source registry software that you can run to create your own private registry.
* Docker Enterprise offers Docker Trusted Registry (DTR), which includes enterprise-level features for managing Docker images.
* To run a basic Docker registry, you can use the `docker run` command with the `registry:2` image, exposing port 5000.
* You can configure the Docker registry using environment variables to customize settings like log levels.
* To enable authentication and secure communication, you can generate an htpasswd file for authentication and create self-signed TLS certificates.
* Docker registries are typically accessed via HTTPS, and self-signed certificates can be used for securing the registry.
* Testing the registry's functionality by making requests to it can help ensure it's set up correctly.
* In the next lesson, you'll learn how to connect to a Docker registry, push and pull images, and effectively use your private registry.



```bash


docker run -d -p 5000 --restart=always --name registry registry:2
# runs a docker registry 

docker logs registry 
# log level is info

docker container strop registry && docker container rm -v registry
# stops the container

docker run -d -p 5000 --restart=always --name registry -e REGISTRY_LOG_LEVEL=debug registry:2
# -e for environment variable

docker logs registry

mkdir ~/registry
cd ~/registry/
mkdir auth
docker run --entrypoint htpasswd registry:2 -Bbn testuser password > auth/htpasswd
ls auth/htpasswd
cat auth/htpasswd

mkdir certs
openssl reg \
-newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \
-x509 -days 365 -out certs/domain.crt
# except default until common name
# common name should be the webaddress 

docker run -d -p 443:443 --restart=always --name registry \
-v /home/cloud_user/registry/certs:/certs \
-v /home/cloud_user/registry/auth:/auth \
-e REGISTRY_HTTP_ADDR=0.0.0.0:443 \
-e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \
-e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \
-e REGISTRY_AUTH=htpasswd \
-e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" \
-e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \
registry:2


curl -k https://localhist:443

```

# using docker registry

* Docker registries are repositories for storing and distributing Docker images.
* Docker provides commands like `docker pull` to download images from a registry and `docker search` to search for images on Docker Hub.
* Authentication may be required to access private registries or private images on Docker Hub. Use `docker login` to authenticate.
* To interact with private registries with self-signed certificates, you can disable certificate verification (not recommended for security) or configure Docker to trust the certificate.
* To configure Docker to trust a self-signed certificate, copy the certificate to the local machine and place it in the directory `/etc/docker/certs.d/<registry_hostname>/`.
* You can push images to a private registry by tagging the image with the registry's hostname and then using `docker push`.
* To pull images from a private registry, ensure the image is not locally available and use `docker pull`.
* Deleting an image with `docker image rm` removes the tag, and you may need to delete the underlying image to ensure a fresh pull from the registry.
* Understanding both insecure methods and secure certificate-based authentication is essential for Docker Certified Associate exam preparation.




```bash

docker search ubuntu
# searches docker hub

docker login
# logs into dockerhub

docker login wboyd4c.mylabserver.com
# logs into private registry 
## fails

# turn off cert verification
sudo vi /etc/docker/daemon.json

##
{
  "insecure-registry": ["wboyd4c.mylabserver.com"]
}
##

sudo systemctl restart docker 
docker login wboyd4c.mylabserver.com

## undo ^ that

sudo mkdir -p /etc/docker/certs.d/wboyd4c.mylabserver.com
sudo scp could_user@wboyd4c.mylabserver.com:/home/cloud_user/registry/certs/domain.crt /etc/docker/certs.d/wboyd4c.mylabserver.com

ls /etc/docker/certs.d/wboyd4c.mylabserver.com/domain.crt

docker login wboyd4c.mylabserver.com
# worked!

docker pull ubuntu 
# pull the ubuntu image

docker tag ubuntu wboyd4c.mylabserver.com/ubuntu
docker push ubuntu wboyd4c.mylabserver.com/ubuntu

docker image rm wboyd4c.mylabserver.com/ubuntu
docker image rm ubuntu 

docker pull wboyd4c.mylabserver.com/ubuntu
# pulls from the private registry 

```

Creating Your Own Docker Image
==============================

Introduction
------------

Docker Hub provides many useful, pre-made images which you can use for a variety of applications. However, if you want to use Docker in the real world, you will likely be required to design and build your own Docker images, either to customize existing images or to run your own software.

In this lab, you will have the opportunity to work with Docker images by designing your own image to a set of specifications using a Dockerfile. You will then be able to run a container using your image to verify that it works.

Solution
--------

1.  Begin by logging in to the lab server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`
ssh cloud_user@54.83.231.10
P50C*miI

### Create a Dockerfile to define the image and build it

1.  Change to the project directory and create a Dockerfile.

`cd ~/fruit-list 
vi Dockerfile`

1.  Build a Dockerfile that meets the provided specifications.

`
FROM nginx:1.15.8

ADD static/fruit.json /usr/share/nginx/html/fruit.json
ADD nginx.conf /etc/nginx/nginx.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
`

1.  Build the image.

`docker build -t fruit-list:1.0.0 .`

### Run a container with the image in detached mode and verify that it works

1.  Run a container in detached mode using the newly-created image.

`docker run --name fruit-list -d -p 8080:80 fruit-list:1.0.0`

1.  Make a request to the container and verify that you get some JSON with a list of fruits.

`curl localhost:8080`

Conclusion
----------

Congratulations — you've completed this hands-on lab!


########################################



Building a Private Docker Registry
==================================

Docker registries provide a powerful way to manage and distribute your Docker images. Docker offers a free registry at Docker Hub, but in many scenarios, you may want greater control of your images, not to mention that it is not free to have more than one private repository on Docker Hub. Fortunately, you can build and manage your own private registries, allowing you full control over where your images are housed and how they can be accessed.

In this lab, you will have the opportunity to work with a private registry. You will build your own private registry, and you will have a chance to practice some advanced setup to ensure that your private registry is secure. After completing this lab, you will know how to set up a simple but secure private Docker registry.

### Solution

Begin by logging in to the lab servers using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

registry server
ssh cloud_user@35.175.171.102
tEdM#)5s

ws server
ssh cloud_user@34.229.74.1
tEdM#)5s


It is a good idea to log in to both servers at the same tab in separate tabs in your terminal application.

### Set up the private registry

1.  In the **Registry** server, create an `htpasswd` file containing the login credentials for the initial account.
    
    `mkdir -p ~/registry/auth`
    
    `
    mkdir -p ~/registry/auth
    docker run --entrypoint htpasswd \
    registry:2.7.0 -Bbn docker d0ck3rrU73z > ~/registry/auth/htpasswd
    `
    
2.  Create a directory to hold the certs for the registry server
    
    `mkdir -p ~/registry/certs`
    
3.  Create a self-signed certificate for the registry. **NOTE:** For the _Common Name_ field, enter the hostname of the registry server, which is `ip-10-0-1-101`. For the other prompts, just hit **enter** to accept the default value.
    
    `
openssl req \
-newkey rsa:4096 -nodes -sha256 -keyout ~/registry/certs/domain.key \
-x509 -days 365 -out ~/registry/certs/domain.crt
    `

ip-10-0-1-101

4.  Create a container to run the registry.
    
    `
docker run -d -p 443:443 --restart=always --name registry \
-v /home/cloud_user/registry/certs:/certs \
-v /home/cloud_user/registry/auth:/auth \
-e REGISTRY_HTTP_ADDR=0.0.0.0:443 \
-e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \
-e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \
-e REGISTRY_AUTH=htpasswd \
-e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" \
-e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \
registry:2.7.0
    `
    
5.  Once the registry starts up, verify that it is responsive. It's OK if this command returns nothing, just make sure it does not fail.
    
    `curl -k https://localhost:443`
    

### Test the registry from the Docker workstation server

1.  Get the public hostname from the registry server. It should be `ip-10-0-1-101`.
    
    `echo $HOSTNAME`
    
2.  On the **Workstation** server, add the registry's public self-signed certificate to `/etc/docker/certs.d`. The `scp` command is copying the file from the registry server to the workstation. The password is the normal `cloud_user` password provided by the lab.
    
    > **Note**: The following steps should be completed from the **Workstation** server.
    
    `sudo mkdir -p /etc/docker/certs.d/ip-10-0-1-101:443`
    
    `sudo scp cloud_user@ip-10-0-1-101:/home/cloud_user/registry/certs/domain.crt /etc/docker/certs.d/ip-10-0-1-101:443`
    
3.  Log in to the private registry from the workstation. The credentials should be username `docker` and password `d0ck3rrU73z`.
    
    `docker login ip-10-0-1-101:443`
    
4.  Test the registry by pushing an image to it. You can pull any image from Docker hub and tag it appropriately to push it to the registry as a test image.
    
    `docker pull ubuntu`
    
    `docker tag ubuntu ip-10-0-1-101:443/test-image:1`
    
    `docker push ip-10-0-1-101:443/test-image:1`
    
5.  Verify image pulling by deleting the image locally and re-pulling it from the private repository.
    
    `docker image rm ip-10-0-1-101:443/test-image:1`
    
    `docker image rm ubuntu:latest`
    
    `docker pull ip-10-0-1-101:443/test-image:1`
    

Conclusion
----------

Congratulations — you've completed this hands-on lab!


# Orchestration 

* Docker swarm uses autolock to protect encryption keys for sensitive data, including raft logs and TLS communication between swarm nodes.
* Autolock is turned off by default, which means encryption keys are stored unencrypted on swarm managers' disks.
* When autolock is enabled, it requires an unlock key to be provided every time Docker restarts on a manager, enhancing security but requiring manual intervention.
* To enable autolock, use the `docker swarm update --autolock=true` command.
* Store the unlock key securely as it's essential for unlocking the swarm after manager restarts.
* You can also enable autolock during swarm initialization using `docker swarm init --autolock=true`.
* Autolock can be disabled using `docker swarm update --autolock=false`.
* To unlock a swarm manager, use `docker swarm unlock` and provide the unlock key when prompted.
* Use `docker swarm unlock-key` to retrieve the unlock key if it's lost but a manager is still unlocked.
* Rotate the unlock key with `docker swarm unlock-key --rotate` for added security. Keep the old key temporarily in case of propagation delays.
* With autolock off, you won't need to unlock the swarm after manager restarts.
* Understanding autolock and its management is important for securing your Docker swarm cluster.


```bash 

docker swarm update --autolock=true
# save the swarm key ... to unlock the logs
# or
docker swarm update --autolock=false
# to keep autolock off

docker node ls
# lists the nodes

sudo systemctl restart docker
# this will lock the swarm 

docker node ls
# error - the swarm is locked 

docker swarm unlock
# enter the swarm key 


docker node ls 
# this worked 

docker swarm unlock-key 
# gives you the unlocked key 

docker swarm unlock-key --rotate
# gives you a new key

docker swarm update --autolock=false
# turn off autolock 
# swarm doesn't need to be unlocked




```

# high availability in a Docker swarm cluster

* High availability in Docker swarm involves multiple managers.
  * Ensures cluster functionality despite manager issues.
* Docker uses Raft consensus algorithm for consistent state.
  * More managers increase fault tolerance but require more communication.
* Quorum means majority (>50%) of swarm managers.
  * Maintaining quorum is essential for making changes.
* Examples illustrate quorum's importance during outages.
* Odd number of swarm managers recommended for fault tolerance.
* Availability zones should have at least 3 zones for redundancy.
  * Distribute swarm managers to maintain quorum if a zone fails.


```bash

docker node ls
# shows nodes

# RAFT Consensus Algorithm
## how many managers can we loose, and still keep afloat ?
## too many would lead to too much network work to keep track of them

# Quarum ... always more than 1/2
# no quarum, then no changes can be made to the swarm 
# always have an odd number of swarm managers
## 3sm ... can loose 1
## 5sm ,,, can loose 2
## 7sm ,,, can loose 3
## 9sm ,,, can loose 4

# Avaliability Zone Distrobution
# 3 | 1-1-1
# 5 | 2-2-1
# 7 | 3-2-2
# 9 | 3-3-3
# spread out the SM nodes, different distrobution centers or different locations

```

# Introduction to Docker Services

* Docker swarm services run applications in a cluster.
  * Defined by a set of replica tasks distributed across nodes.
* Tasks are containers; services are collections of tasks.
* Create services with `docker service create`.
  * Similar to `docker run` with additional options.
* Expose ports, use templates for dynamic values.
* Manage services with commands like `docker service ls`.
  * Inspect services with `docker service inspect`.
  * Update services with `docker service update`.
  * Scale services with `docker service scale`.
* Replicated services use a fixed number of replicas.
* Global services create one task on each node.


```bash

dcoker service create nginx
# creates a service on the nginx image

docker service create --name nginx --replicas 3 -p 8080:80 nginx
# creates 3 replicas, with an exposed port

curl localhost:8080
# shows it's running

###

docker service create --name node-hostname --env NODE_HOSTNAME="{{.NODE.Hostname}}" --replicas 3 nginx 
# creates a service with 3 replicas and they have the hostname as an environment variable

docker ps
# shows containers

docker exec <container id> printenv
# prints the environment variables

###

docker service ls
# list services


docker service ps nginx
# shows us the tasks of the service

docker service inspect nginx
# json output of the service

docker service inspect --pretty nginx
# shows it pretty 

docker service update --replicas 2 nginx
# update replicas

docker service rm nginx
# removes the service ... everything under the service will be removed also

docker service create --name nginx --mode global nginx
# creates 1 service on each node of the cluster 

docker service rm nginx 
# removes the service

###

docker service update --replicas 3 
# scales the to 3 replicas


docker service scale nginx=4
# scales up the service 


docker service ps nginx
# shows the replicas




```

# Using docker inspect

* Docker inspect provides detailed info about Docker objects.
  * Works for containers, images, and services.
* Use `docker inspect <ID>` or `docker inspect <NAME>`.
* Object-specific versions available:
  * `docker container inspect <NAME/ID>`
  * `docker service inspect <NAME/ID>`
* Some versions support `--pretty` flag for readable output.
* `--format` flag allows custom output formatting.
  * Utilizes Go templates for specific field extraction.
* Useful for troubleshooting and managing Docker objects.


```bash 

docker run -d --name nginx nginx

docker inspect <container id>

docker container ls
# list containers
docker inspect <container id>

docker image ls
# docker image list
docker inspect <image id>

docker service create --name nginx-csv nginx 

docker inspect <service id>

docker container inspect <id>

docker service inspect <id>

docker service inspect --pretty <id>
# more readable 

docker container inspect --pretty <id>
# doesn't work 

###

docker service inspect nginx-svc
docker service inspect --format='{{.ID}}' nginx-svc
# gives ID only 



```

# docker compose

* Docker Compose manages multi-container apps.
* Multi-container apps run different images.
* Define apps in a declarative docker-compose.yml file.
* Services specify containers and options.
* Use `docker-compose up` to run the app.
* `docker-compose down` stops and removes the app.
* Useful for development and testing.


```bash

sudo curl -L "https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(una
sudo chmod +x /usr/local/bin/docker-compose
docker-compose version

mkdir nginx-compose
cd nginx-compose
vi docker-compose.yml
#
# Docker Compose version 3
version: '3'
# Define services for our multi-container application
services:
  # Web service using the official Nginx image
  web:
    image: nginx
    ports:
      - "8080:80"  # Map host port 8080 to container port 80
  # Redis service using the official Redis image (alpine version)
  redis:
    image: redis:alpine
#

docker-compose up -d

docker-compose ps
docker-compose down



```


# docker stacks

* Docker Stacks Overview
  * Manage multi-container apps
  * Interact within a Docker Swarm
* Similar to Docker Compose
  * Run multi-container apps on a single host
  * Stacks run as services in a Docker Swarm
* Stack Creation and Management
  * Use docker stack deploy
  * List stacks with docker stack ls
  * View service tasks with docker stack ps
  * List services in a stack with docker stack services
  * Access service logs with docker service logs
  * Removing a stack with docker stack rm
* Configuring Stacks
  * Define services and replicas in a .yml file
  * Set environment variables for services
  * Publish ports to expose services
  * Enable communication between services in the stack
* Scaling Services
  * Scale services using replicas
  * Easily adjust the number of service instances
* Deleting Stacks
  * Remove a stack and its associated resources
* Exploring Docker Stack Features
  * Numerous features beyond this overview
  * Consult Docker documentation for details


```bash

vi simple-stack.yml
#
version: '3'
service:
    web:
        image: nginx
    busybox:
        image: radial/busyboxplus:curl
        command: /bin/sh -c "while true; do echo hello!; sleep 10; done"
#

docker stack deploy -c simple-stack.yml simple
# creates a stack

docker stack ls
# lists the stacks

docker stack ps simple
# shows the tasks

docker stack services simple
# shows the services

docker service logs <name of service>
# shows the logs from the service

vi simple-stack.yml
#
version: '3'
service:
    web:
        image: nginx
    busybox:
        image: radial/busyboxplus:curl
        command: /bin/sh -c "while true; do echo $$MESSAGE; sleep 10; done"
        environment:
        - MESSAGE=Hello!
#
docker stack deploy -c simple-stack.yml simple

vi simple-stack.yml
#
version: '3'
service:
    web:
        image: nginx
        ports:
        - "8080:80"
    busybox:
        image: radial/busyboxplus:curl
        command: /bin/sh -c "while true; do echo $$MESSAGE; sleep 10; done"
        environment:
        - MESSAGE=Hello!
#
docker stack deploy -c simple-stack.yml simple

vi simple-stack.yml
#
version: '3'
service:
    web:
        image: nginx
        ports:
        - "8080:80"
    busybox:
        image: radial/busyboxplus:curl
        command: /bin/sh -c "while true; do echo $$MESSAGE; curl web:80; sleep 10; done"
        environment:
        - MESSAGE=Hello!
#
docker stack deploy -c simple-stack.yml simple

curl localhost:8080
# test 

docker service logs simple_busybox
# shows the logs for busybox


vi simple-stack.yml
#
version: '3'
service:
    web:
        image: nginx
        ports:
        - "8080:80"
        deploy:
            replicas: 3
    busybox:
        image: radial/busyboxplus:curl
        command: /bin/sh -c "while true; do echo $$MESSAGE; curl web:80; sleep 10; done"
        environment:
        - MESSAGE=Hello!
#
docker stack deploy -c simple-stack.yml simple

docker stack ps simple
# shows the tasks

docker stack rm simple
# delete/remove stack



```

# Node labels

* Node Labels in Docker Swarm
  * Metadata for nodes
  * Control task execution
* Use Case Example
  * Managing tasks across zones
* Adding Labels to Nodes
  * `docker node update --label-add`
  * Key-value pairs for labels
* Viewing Node Labels
  * `docker node inspect`
  * Lists existing labels
* Controlling Task Placement
  * `--constraint` for specific labels
  * `==` for label equality
  * `!=` for label inequality
  * Constraints with `docker service create`
* Evenly Balancing Tasks
  * `--placement-pref` for task distribution
  * Spreading tasks across label values


```bash

docker node ls
# lists nodes

docker node update  --label-add availability_zone=east <node0 name>
docker node update  --label-add availability_zone=west <node1 name>

docker node inspect --pretty <node0 name>
docker node inspect --pretty <node1 name>

###

docker service create --name nginx-east --constraint node.label.availability_zone==east --replicas 3 nginx
docker service ps nginx-east

docker service create --name nginx-west --constraint node.label.availability_zone!=east --replicas 3 nginx
docker service ps nginx-west

###

docker service create --name nginx-spread --placement-pref spread=node.label.availability_zone --replicas 3 nginx

docker service ps nginx-spread
# shows the services 

docker service rm nginx-spread
#removes the services

```


# Lab -- Building services in Docker


Building Services in Docker
===========================

Introduction
------------

Services are the most basic and straightforward way to run containers using a Docker swarm. They allow you to execute multiple replica containers across all nodes in the Swarm cluster.

In this lab, you will have the opportunity to work with Docker services. You will practice scaling services by changing the number of replicas for an existing service. You will also have the opportunity to create a new service and run it in the cluster.

Solution
--------

1.  Begin by logging in to the lab server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

ssh cloud_user@3.238.93.105
&5!3Z_nw

ssh cloud_user@34.201.9.203
&5!3Z_nw

ssh cloud_user@44.200.229.18
&5!3Z_nw


### Scale the `products-fruit` service to 5 replicas

1.  Scale the service.

`docker service update --replicas 5 products-fruit`

You can also do it this way (both do the same thing):

`docker service scale products-fruit=5`

### Create the `products-vegetables` service

1.  Create the `products-vegetables` service.

`docker service create --name products-vegetables -p 8081:80 --replicas 3 linuxacademycontent/vegetable-service:1.0.0`

1.  Verify that the service is working.

`curl localhost:8081`

You should see some JSON data containing a list of vegetables.

Conclusion
----------

Congratulations — you've completed this hands-on lab!


# another Lab

Building a Docker Application Stack
===================================

Introduction
------------

Stacks are one of the most powerful orchestration features available in Docker Swarm. They allow you to easily manage complex applications consisting of multiple interdependent components running in separate containers.

In this lab, you will have the opportunity to work with Docker stacks by building a multi-component application as a Docker stack. You will also learn how to manage existing stacks by scaling a stack's services after it has already been deployed. This will give you some hands-on insight into Docker stacks.

Solution
--------

1.  Begin by logging in to the lab server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

ssh cloud_user@44.208.164.125
^tbM6^rt

### Build and deploy the application stack

1.  Create an empty project directory with a Docker compose YAML file inside.

`
cd ~/
mkdir produce
cd produce
vi produce.yml
`

1.  Build a stack definition in `produce.yml` to meet the provided specifications.

`
version: '3'
services:
   fruit:
     image: linuxacademycontent/fruit-service:1.0.1
   vegetables:
     image: linuxacademycontent/vegetable-service:1.0.0
   all_products:
     image: linuxacademycontent/all-products:1.0.0
     ports:
     - "8080:80"
     environment:
     - FRUIT_HOST=fruit
     - FRUIT_PORT=80
     - VEGETABLE_HOST=vegetables
     - VEGETABLE_PORT=80
`

1.  Deploy the stack using the compose file.

`docker stack deploy -c produce.yml produce`

1.  Verify that the stack is working.

`curl localhost:8080`

Note that after deploying, it may take a few moments for the stack to become responsive. You can check the status of the services with `docker stack services produce`. Once the services are up and running, you should get some JSON data containing a combined list of fruits and vegetables.

### Scale the _Fruit_ and _Vegetable_ services in the stack

1.  Set the number of replicas to `3` for the _Fruit_ and _Vegetable_ services in the compose file.

`vi produce.yml`

`
vi produce.yml
version: '3'
services:
   fruit:
     image: linuxacademycontent/fruit-service:1.0.1
     deploy:
       replicas: 3
   vegetables:
     image: linuxacademycontent/vegetable-service:1.0.0
     deploy:
       replicas: 3
   all_products:
     image: linuxacademycontent/all-products:1.0.0
     ports:
     - "8080:80"
     environment:
     - FRUIT_HOST=fruit
     - FRUIT_PORT=80
     - VEGETABLE_HOST=vegetables
     - VEGETABLE_PORT=80
     `

1.  Redeploy the stack using the compose file.

`docker stack deploy -c produce.yml produce`

1.  Verify that the stack is still working.

`curl localhost:8080`

You should get some JSON data containing a combined list of fruits and vegetables.

Use `docker stack services produce` to see that the number of replicas for the _Fruit_ and _Vegetable_ services is now 3.

Conclusion
----------

Congratulations — you've completed this hands-on lab!


# Storage and Volumns

* Docker Storage Concepts
  * Storage drivers (graph drivers)
  * Depends on OS and config
* Major Storage Drivers
  * Overlay2 (default for Ubuntu, CentOS, Red Hat)
  * Aufs (for older Ubuntu versions)
  * Devicemapper (for older CentOS)
* Storage Models
  * Filesystem Storage
    * Efficient memory usage
    * Less efficient for frequent writes
  * Block Storage
    * Requires separate block storage device
    * Efficient with write-heavy workloads
  * Object Storage
    * External to containers
    * Requires application integration
* Layered File System
  * Composed of multiple layers
  * Located on Docker host
  * Use `docker inspect` to find layer data


```bash


docker run --name storage_nginx nginx 

docker container inspect storage_nginx

sudo -i 
cd /var/lib/.../
ls
# directories

###

docker image inspect nginx


```

# configur devicemapper

* Configuring DeviceMapper for Docker
  * Supported by CentOS 7 and earlier
  * Customize using daemon config file
* DeviceMapper Modes
  * Loop-LVM (Default)
    * Uses loopback mechanism
    * Not recommended for production
  * Direct-LVM (Recommended)
    * Requires additional storage device
    * More efficient for production
* Steps to Configure Direct-LVM
  1. Add an additional storage device (e.g., /dev/xvdb)
  2. Stop and disable Docker
  3. Delete existing Docker data
  4. Edit daemon.json to configure DeviceMapper
  5. Enable and start Docker
* Verify Configuration
  * Check Docker info for storage driver and mode
  * Test by running a container (e.g., `docker run hello-world`)


```bash

docker info

sudo systemctl disable docker
sudo systemctl stop docker
sudo rm -rf /var/lib/docker
sudo vi /etc/docker/daemon.json
#
{
"storage-driver": "devicemapper",
"storage-opts": [
  "dm.directlvm_device=/dev/nvme1n1",
  "dm.thinp_percent=95",
  "dm.thinp_metapercent=1",
  "dm.thinp_autoextend_threshold=80",
  "dm.thinp_autoextend_percent=20",
  "dm.directlvm_device_force=true"
]
#

sudo systemctl enble docker 
sudo systemctl start docker

docker info
# see the new storage driver

docker run hello-world



```


# Docker Volumes

* Docker Volumes
  * Ensuring persistent data
  * Two types: Bind Mounts and Volumes
* Bind Mounts
  * Map host path to container
  * Less portable
  * Suitable for specific host data
* Volumes
  * Docker manages storage location
  * More portable
  * Ideal for container storage
  * Shareable among containers
* Creating Volumes
  * Use `--mount` or `-v` syntax
  * Bind Mount Example: `--mount type=bind,source=/host/path,destination=/container/path`
  * Volume Example: `--mount type=volume,source=volume_name,destination=/container/path`
* Sharing Volumes
  * Multiple containers can use the same volume
  * Achieved by using the same volume name
* Managing Volumes
  * Create: `docker volume create volume_name`
  * List: `docker volume ls`
  * Inspect: `docker volume inspect volume_name`
  * Delete: `docker volume rm volume_name`


```bash

cd ~/
mkdir message 
echo helloworld > message/message.txt
cat message/message.txt
# shows helloworld

docker run --mount type=bind,source=/home/cloud_user/message,destination=/root,readonly busybox cat /root/message.txt
# runs a container with a mounted directory and is able to read the file from it

docker run --mount type=volume,source=my-volume,destination=/root busybox sh -c 'echo hello > /root/message.txt && cat /root/message.txt'
# runs a container with a volume, and writes and reads to that volume


docker run -v /home/cloud_user/message:/root:ro busybox cat /root/message.txt 
docker run -v my-volume:/root busybox cat /root/message.txt


docker run --mount type=volume,source=shared-volume,destination=/root busybox sh -c 'echo I wrote this' > /root/message.txt
docker run --mount type=volume,source=shared-volume,destination=/anotherplace busybox cat /anotherplace/message.txt
# shows the volume being shared 


docker volume create VOLUME_NAME
docker volume ls

docker volume inspect VOLUME_NAME

docker volume rm VOLUME_NAME



```

# image cleanup

* Docker Image Cleanup
  * Managing storage on Docker hosts
* docker system df
  * Shows storage usage breakdown
  * Includes images, containers, volumes, and build cache
* docker system df -v
  * Provides detailed info on images, containers, and volumes
* docker image prune
  * Removes unreferenced images
  * Frees up storage space
* docker image prune -a
  * Deletes images with no containers
  * Helpful for unused images


This summary covers Docker image cleanup, including commands like docker system df, docker system df -v, docker image prune, and docker image prune -a for managing storage and removing unused images on Docker hosts.


```bash

docker system df
# info on data in docker
docker system df -v
# more detail with the -v

docker image prune
# removes un-used image data
docker image prune -a
# with -a only removes if it's not used in a container



```


# Storage in a Cluster

* Storage in a Docker Swarm Cluster
  * Using Docker volumes within a swarm cluster
* Options for Storing Data in a Swarm Cluster
  * Application logic for external object storage
  * Using a volume driver for external volumes
* Setting Up External Storage
  * Installing the SSHFS Docker plugin
  * Creating an external storage directory
* Creating a Custom Volume
  * Using docker volume create with a custom driver
  * Specifying SSH commands and passwords
* Creating a Service with External Volume
  * Using docker service create with custom volume settings
  * Automatically creating volumes on cluster nodes
* Understanding Volume Creation in a Cluster
  * Explaining how volumes are created on nodes
  * Automatic volume creation in a cluster
* Summary
  * Basics of using external storage and volumes in a Docker Swarm Cluster


```bash


mkdir /home/cloud_user/external 
ls

cd external/
echo External STorage > /home/cloud_user/external/message.txt

docker volume create --driver  vieux/sshfs \ 
-o sshcmd=cloud_user@<private ip>:/home/cloud_user/external \
-o password=<password> \
sshvolume

docker volume ls

docker service create --mount source=sshvolume
# does not work 

docker service create --replicas=3 --name storage-service --mount volume-driver=vieux/sshfs,source=cluster-volume,destination=/app,volume-opt=sshcmdcloud-user@<ip>:/home/cloud_user/external,volume-opt=password=<password> busybox cat /app/message.txt


docker service logs storage-service

```

# LAB : Using Volumes in Docker Containers

Using Volumes in Docker Containers
==================================

Introduction
------------

Containers are designed to be ephemeral, so when you need persistent data, it is usually not a good idea to store it directly in the container's file system. This is where Docker volumes come into play. Docker volumes allow you to store persistent data outside the container itself, providing greater flexibility in what you can do with your data.

In this lab, you will have the opportunity to solve a complex problem using Docker volumes. You will have a chance to work with both shared volumes and bind mounts in order to implement two containers which work together, one container transforming data created by the other. This will give you some practice in working with volumes, as well as some insight into the many ways in which Docker volumes can be used.

Solution
--------

1.  Begin by logging in to the lab server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

ssh cloud_user@44.198.55.20
%4SvSrL0


### Create the Shared Volume and Counter Container

1.  Create a shared volume.

`docker volume create test-data`

1.  Create the `counter` container with the provided command, and mount the shared volume to the container.

`
docker run --name counter -d \
  --mount type=volume,source=test-data,destination=/var/log/test \
  busybox \
  sh -c 'i=0; while true; do echo "$i: $(date)" >> /var/log/test/1.log; i=$((i+1)); sleep 1; done'
`

You can confirm that the `counter` container is generating data by examining the file inside the container:

`docker exec counter cat /var/log/test/1.log`

### Create the `fluentd` Container

1.  Create the `fluentd` container and mount the shared volume, the config file, and the output directory to it.

`
docker run --name fluentd -d \
  --mount type=volume,source=test-data,destination=/var/log/input \
  --mount type=bind,source=/etc/fluentd/fluent.conf,destination=/fluentd/etc/fluent.conf \
  --mount type=bind,source=/etc/fluentd/output,destination=/var/log/output \
  --env FLUENTD_ARGS="-c /fluentd/etc/fluent.conf" \
  k8s.gcr.io/fluentd-gcp:1.30
`

1.  Verify that the `fluentd` container is generating output on the Docker host.

`ls /etc/fluentd/output`

You should see some files containing the transformed log data.

Conclusion
----------

Congratulations — you've completed this hands-on lab!


# Lab : Using Storage Volumes with Docker Swarm

Using Storage Volumes with Docker Swarm
=======================================

Introduction
------------

Storage volumes provide a powerful and flexible way to add persistent storage to your containers, but what if you need to share storage volumes across multiple Docker hosts, such as a Swarm cluster? In this lab, you will have the opportunity to work with a simple method of creating shared volumes usable across multiple swarm nodes using the `sshfs` volume driver.

Solution
--------

1.  Begin by logging in to the `storage` server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

* Swarm Manager
ssh cloud_user@3.82.251.51
7#4I9Vx0

* Worker1
ssh cloud_user@100.27.20.200
7#4I9Vx0

* Storage Server
ssh cloud_user@52.23.208.113
7#4I9Vx0



### Set up the External Storage Location

1.  On the storage server, create the storage directory.

`sudo mkdir -p /etc/docker/storage 
sudo chown cloud_user:cloud_user /etc/docker/storage`

1.  Copy the nginx configuration file into the storage directory.

`cp /home/cloud_user/nginx.conf /etc/docker/storage/`

### Install the `vieux/sshfs` Plugin

1.  Install the `vieux/sshfs` plugin on the **swarm manager** and **worker node**.

`docker plugin install --grant-all-permissions vieux/sshfs`

### Create the nginx Service That Uses the Shared Volume

1.  Create the `nginx-web` service on the **swarm manager**.

Create the container. Be sure to replace `<cloud_user password>` with the actual password.

`
docker service create -d \
   --replicas=3 \
   --name nginx-web \
   -p 8080:9773 \
   --mount volume-driver=vieux/sshfs,source=nginx-config-vol,target=/etc/nginx/,volume-opt=sshcmd=cloud_user@10.0.1.103:/etc/docker/storage,volume-opt=password="7#4I9Vx0" nginx:latest

`

1.  Verify that the service is working properly.

`curl localhost:8080`

If everything is set up correctly, you should see HTML from the nginx _Welcome_ page.

Conclusion
----------

Congratulations — you've completed this hands-on lab!


# Docker Networking

* Docker Container Networking Model (CNM)
  * Describes Docker's networking structure
  * Multiple implementations exist
* Components of CNM
  * Sandbox: Isolated network unit for a container
  * Endpoint: Connects containers to networks
    * Containers can have multiple endpoints
  * Network: Connects multiple endpoints
* Implementing CNM
  * Docker Engine controls networking
  * Network drivers for implementation
  * IPAM driver manages IP addresses
  * Underlying network infrastructure
* Examples of CNM implementations
  * Bridge network (within a single host)
  * Overlay network (across multiple hosts)
* CNM basics for Docker networking

# Built-In Network Drivers

* Docker Built-In Network Drivers
  * Different networking implementations
  * Native network drivers in Docker:
    * Host
      * simple, 
      * 1 host
      * no isolation 
    * Bridge (default)
      * 1 to 1 connection on a single host 
    * Overlay (for multi-host setups)
      * good for between containers in a swarm
    * MACVLAN (low latency)
      * 
    * None (manual setup)
* Determining Network Drivers
  * Use `--net` with `docker run`
  * Or use `--driver` with `docker network create`
* Host Network Driver
  * Uses host network stack directly
  * No isolation between containers
  * Suitable for simple setups
* Bridge Network Driver
  * Default driver in Docker
  * Connects containers on the same host
  * Suitable for isolated networking on a single host
* Overlay Network Driver
  * Connects containers across multiple hosts (Docker Swarm)
  * Uses VXLAN data plane for transparent communication
* MACVLAN Network Driver
  * Low latency option
  * Directly connects container interfaces to host interfaces
  * Requires more configuration, can be complex
* None Network Driver
  * Provides container sandboxing but no networking
  * Manual setup required for connectivity
* Use Cases
  * Choose the driver based on network requirements
  * Host: Simple setups or few containers
  * Bridge: Isolated networking on a single host
  * Overlay: Multi-host communication in Docker Swarm
  * MACVLAN: Low latency or external sub-net needs
  * None: Full manual control or no container networking


```bash

# host 
docker run -d --net host --name host_busybox radial/busyboxplus:curl sleep 3600
docker run -d --net host --name host_nginx nginx
ip add | grep eth0
docker exec host_busybox ip add | grep eth0
docker exec host_busy


# Bridge
ip link
docker network create --driver bridge my-bridge-net
ip link
docker run -d --name bridge_nginx --network my-bridge-net nginx
docker run --rm --name bridge_busybox --network my-bridge-net radial/busyboxplus:curl curl bridge_nginx:80


# Overlay 
docker network create --driver overlay my-overlay-net
docker service create --name overlay_nginx --network my-overlay-net nginx
docker service create --name overlay_busybox --network my-overlay-net radial/busyboxplus:curl sh -c 'curl overlay_nginx'
docker service logs overlay_busybox

# MacLAN
docker network create -d macvlan --subnet 192.168.0.0/24 --gateway 192.168.0.1 -o parent=eth0 my-macvlan-net
docker run -d --name macvlan_nginx --net my-macvlan-net nginx
docker run --rm --name macvlan_busybox --net my-macvlan-net radial/busyboxplus:curl curl 192.168.0.2:80


# None
docker run --net none -d --name none_nginx nginx
docker run --rm radial/busyboxplus:curl curl none_nginx:80


```


# creating a docker bridge network

* Explore Docker Bridge Networks
* Learn network management commands
* Create a network using docker network create
* Connect containers to a network
* Use embedded DNS for container name resolution
* Create network aliases
* Manage networks with Docker commands
* Inspect network details with docker network inspect
* Disconnect containers from a network
* Remove a network after disconnecting containers


```bash

docker network create my-net
# creates the network

docker run -d --name my-net-busybox --network my-net radial/busyboxplus:curl sleep 3600
# container using the network

docker run -d --name my-net-nginx nginx
# another container 

docker network connect my-net my-net-nginx
# connect the container to the network

docker exec my-net-busybox curl my-net-nginx:8080
# execute using crul


###

docker run -d --name my-net-nginx2 --network my-net --network-alias my-nginx-alias nginx
# create a container, connect it, and set alias to use it 

docker exec my-net-busybox curl my-net-nginx2:8080
docker exec my-net-busybox curl my-nginx-alias:8080

###

docker run -d --name my-net-nginx3
docker network connect --alias another-alias my-net my-net-ginx3


docker exec my-net-busybox curl another-alias:8080

###

docker network ls
# list out the net work


docker network inspect my-net 
# shows details on the network

docker network disconnect my-net my-net-nginx
# disconnects the network

docker network rm my-net 
# remove the network 
# need to disconnect all the networks... then you can remove

```


# deploying a service on a docker overlay network

* Explore Docker Overlay Networks
* Enable communication across Docker hosts
* Default overlay network: "ingress"
* Create custom overlay networks
* Use "docker network create" with "--driver overlay"
* Attach containers manually with "--attachable"
* Deploy services on custom overlay networks
* Demonstrate communication across the custom overlay network
* Utilize embedded DNS for name resolution

```bash

docker network create --driver overlay --attachable my-overlay
# create a network

docker service create --name overlay-service --network my-overlay --replicas 3 nginx
# create a service and use the network

docker run --rm --network my-overlay radial/busyboxplus:curl curl overlay-service:80


```

# Exposing Containers Externally


* Exposing containers externally
  * Access containers from outside
  * Publish ports with `-p` flag
* Use `docker port` to list published ports
* Examine published ports with `docker ps`
* Two service publishing modes
  * Ingress: Routing mesh for load balancing
  * Host: Publishes port directly on the host
* Host mode limitations
  * Only 1 replica per node
  * Limited use cases
  * Suitable for global services


```bash


docker run -d -p 8080:80 --name nginx-pub nginx
curl localhost:8080

docker port nginx_pub
# shows the published ports

docker ps 
# also shows the published ports

###

docker service create -p 8081:80 --name nginx-ingress_pub nginx
# create a service with ingress

curl localhost:8081

docker service ps nginx_ingress_pub
# any node will respond, due to mesh created 

###

docker service create -p mode=host,published=8082,target=80 --name nginx_host_pub nginx
# create service with a local host

docker service ps nginx_host_pub
curl localhost:8082
# this will only work on this node... since it's "HOST"


```


# network trouble shooting

* Network Troubleshooting Tools
  * Use logs for information
    * Access container logs with `docker logs`
    * Access service logs with `docker service logs`
    * Check Docker daemon logs with `journalctl`
  * Utilize Netshoot container
    * Contains common network troubleshooting tools
  * Test network with Netshoot
    * Attach Netshoot to networks for troubleshooting
    * Insert Netshoot into container sandboxes
  * Troubleshooting Techniques
    * Use Netshoot to simulate network interactions
    * Troubleshoot containers with no network connectivity



```bash

docker run --name log-container busybox echo here is my container log
# create a container

docker logs log-container
# view log


docker service create --name log-svc --replicas 3 -p 8080:80 nginx
# create a service

curl localhost:8080
# 

docker service logs log-svc

###

sudo journalctl -u docker 
# show the docker deamon log

###

docker network create custom-net 
docker run -d custom-net-nginx --network custom-net nginx

docker run --rm --network custom-net nicolaka/netshoot curl custom-net-nginx:80
# netshoot can test things in the network


docker run --rm --network container:custom-net-nginx nicolaka/netshoot curl localhost:80
# inserts a container inside a custom-net-nginx's sandbox

```

# Customizing Docker DNS

* Customizing Docker DNS
  * DNS maps hostnames to IP addresses.
  * Customize Docker's DNS settings.
    * Edit `/etc/docker/daemon.json`.
    * Set DNS servers in the JSON configuration.
  * Restart Docker daemon after changes.
* Testing Custom DNS
  * Use `nslookup` in a container.
  * Verify custom DNS server settings.
* Per-Container DNS Override
  * Override DNS for a specific container.
  * Use the `--dns` flag with `docker run`.

```bash

sudo vi /etc/docker/daemon.json
#
{
"dns": ["8.8.8.8"]
}
#

sudo systemctl restart docker
docker run nicolaka/netshoot nslookup google.com


docker run --dns 8.8.4.4 nicolaka/netshoot nslookup google.com


```


# Lab Using a Docker Bridge Network

Video 1 of 2

Introduction
------------

Previous

Previous Video

Next

Next Video

This video introduces the scenario for the lab and guides you toward some additional resources to help you complete it.

Using a Docker Bridge Network
=============================

Introduction
------------

By default, all containers on a host can communicate with one another over a default bridge network. However, in some cases, you may want to isolate groups of containers by allowing them to communicate over their own isolated network.

In this lab, you will have the opportunity to create a custom bridge network designed to facilitate communication between containers on a Docker host.

Solution
--------

1.  Begin by logging in to the lab server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

ssh cloud_user@18.212.118.169
+2)VlNoB

### Create the Bridge Network

1.  Create a bridge network called `prices-net`.

`docker network create --driver bridge prices-net`

### Create the `base-price` Container

1.  Create a container for the component that serves base prices.

`docker run --name base-price -d --network prices-net linuxacademycontent/prices-base-price:1`

### Create the `sales` Container

1.  Create a container for the component that serves products on sale.

`docker run --name sales -d --network prices-net linuxacademycontent/prices-sales:1`

### Create the `total-price` Container

1.  Create a container for the component that serves the total prices of products.

`docker run --name total-price -d --network prices-net -p 8080:80 linuxacademycontent/prices-total-price:1`

1.  Verify that everything is set up correctly.

`curl localhost:8080`

You should get a list of products and their final prices. The `total-prices` container calculates these prices by first querying the other two containers. This communication takes place over the `prices-net` bridge network.

Conclusion
----------

Congratulations — you've completed this hands-on lab!

# Deploying a Service on an Overlay Network

Deploying a Service on an Overlay Network
=========================================

Introduction
------------

Bridge networks are a powerful tool for controlling communication between containers on a single host, but what if you need to provide isolated networking between containers in Docker Swarm? With Docker Swarm, you can use custom overlay networks to allow groups of containers to communicate transparently, even if they are running on different swarm nodes.

In this lab, you will have the opportunity to work with overlay networks. You will set up a custom overlay network and deploy three different services that communicate with each other using this network.

Solution
--------

1.  Begin by logging in to the lab server using the credentials provided on the hands-on lab page:

`ssh cloud_user@PUBLIC_IP_ADDRESS`

* Swarm Manager
ssh cloud_user@18.212.113.159
_uUJ25m]

* worker1
ssh cloud_user@52.55.57.232
_uUJ25m]

* worker2
ssh cloud_user@52.90.217.118
_uUJ25m]



### Create the Overlay Network

1.  Create the `prices-overlay-net` overlay network.

`docker network create --driver overlay prices-overlay-net`

### Create the `base-price` Service

1.  Create the `base-price` service.

`docker service create --name base-price --network prices-overlay-net --replicas 3 linuxacademycontent/prices-base-price:1`

### Create the `sales` Service

1.  Create the `sales` service.

`docker service create --name sales --network prices-overlay-net --replicas 3 linuxacademycontent/prices-sales:1`

### Create the `total-price` Service

1.  Create the `total-price` service.

`docker service create --name total-price --network prices-overlay-net --replicas 2 -p 8080:80 linuxacademycontent/prices-total-price:1`

1.  Verify that you get the total price data.

`curl localhost:8080`

You should see a list of products and the total price for each. These prices are calculated by communicating with the `base-price` and `sales` services using the custom overlay network.

Conclusion
----------

Congratulations — you've completed this hands-on lab!

# Security

* Docker Content Trust (DCT)
  * Ensures container image integrity.
  * Similar to signing software for security.
* Sign and Push
  * Generate trust key with Docker Hub username.
  * Add yourself as a signer to a repository.
  * Build, tag, sign, and push a Docker image.
* Enabling DCT
  * Set `DOCKER_CONTENT_TRUST=1`.
  * Unsigned images won't run.
* Disabling DCT
  * Set `DOCKER_CONTENT_TRUST=0`.
  * Allows running signed and unsigned images.

```bash

docker login
# password

cd ~/
# go home


docker trust key generate <username>
# enter passphrase
# this will generate a trust key 

docker trust signer add --key <username>.pub <username> <username>/<name>
# root passphrase
# repo passphrase
# then you will be a trusted signer


mkdir ~/dct-test
cd dct-test
vi Dockerfile
#
FROM busybox:latest
CMD echo It worked!
#

docker run <your docker hub username>/dct-test:unsigned
# unsigned version

export DOCKER_CONTENT_TRUST=1
docker run <your docker hub username>/dct-test:unsigned
# errors due to trust 


docker build -t <your docker hub username>/dct-test:signed .
docker trust sign <your docker hub username>/dct-test:signed

export DOCKER_CONTENT_TRUST=1
docker run <your docker hub username>/dct-test:signed
# works due to trusted



```


# Default Docker Engine Security

* Namespaces and Control Groups
  * Provide isolation for containers.
  * Prevent processes from affecting others.
  * Enhance security by limiting exploit impact.
* Docker Daemon Attack Surface
  * Docker daemon requires root privileges.
  * Be cautious with user and process access.
  * Restrict access to trusted entities.
* Linux Kernel Capabilities
  * Fine-grained permissions in Linux.
  * Used by Docker to grant specific abilities.
  * Enhance security by avoiding unnecessary privileges.


```bash


```

# Security MTLS

* Encrypting Overlay Networks
  * Use `--opt encrypted` with `docker network create`.
  * Provides secure communication between containers.
* Mutual TLS (MTLS) in Docker Swarm
  * Both client and server have certificates.
  * All swarm-level communication is encrypted.
  * Certificates are generated by a certificate authority (CA).
  * Enabled by default for cluster communication.


```bash

docker network create --opt encrypted --driver overlay my-encryptwd-net
docker service create --name cencrypted-overlay-nginx --network my-encrypted-net --replicas 3 nginx

docker service create --name encrypted-overlay-busybox --network my-encrypted-net radial/busyboxplus:curl sh -c 'curl encrypted-overlay-nginx:80 sleep 3600'

docker service logs encrypted-overlay-busybox

```


# Securing the Docker Daemon HTTP Socket

* Secure Docker Daemon Socket
  * Docker listens on a non-exposed socket by default.
  * Exposing it requires additional security measures.
  * Generate a certificate authority (CA) and certificates.
  * Set permissions for sensitive key files.
  * Configure Docker daemon to use certificates.
  * Modify Docker daemon unit file.
* Copy Certificates to Client
  * Copy CA, client certificate, and client key to the client.
  * Place them in the `~/.docker` directory.
* Configure Docker Client
  * Set `DOCKER_HOST` to the server's IP and port.
  * Set `DOCKER_TLS_VERIFY` to 1.
  * Test connection to the remote Docker daemon.


```bash

openssl genrsa -aes256 -out ca-key.pem 4096
openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem -subj "/C=US/ST=Texas/L=Keller/O=Linux Academy/OU=Content/CN=$HOSTNAME"
openssl genrsa -out server-key.pem 4096
openssl req -subj "/CN=$HOSTNAME" -sha256 -new -key server-key.pem -out server.csr
echo subjectAltName = DNS:$HOSTNAME,IP:<server private IP>,IP:127.0.0.1 >> extfile.cnf
echo extendedKeyUsage = serverAuth >> extfile.cnf
openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \
-CAcreateserial -out server-cert.pem -extfile extfile.cnf

openssl genrsa -out key.pem 4096
openssl req -subj '/CN=client' -new -key key.pem -out client.csr
echo extendedKeyUsage = clientAuth > extfile-client.cnf
openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \
-CAcreateserial -out cert.pem -extfile extfile-client.cnf

chmod -v 0400 ca-key.pem key.pem server-key.pem
chmod -v 0444 ca.pem server-cert.pem cert.pem


sudo vi /etc/docker/daemon.json
#
{
"tlsverify": true,
"tlscacert": "/home/cloud_user/ca.pem",
"tlscert": "/home/cloud_user/server-cert.pem",
"tlskey": "/home/cloud_user/server-key.pem"
}
#

sudo vi /lib/systemd/system/docker.service
#
ExecStart=/usr/bin/dockerd -H=0.0.0.0:2376 --containerd=/run/containerd/containerd.sock
#

sudo systemctl daemon-reload
sudo systemctl restart docker

scp ca.pem cert.pem key.pem cloud_user@<client private IP>:/home/cloud_user

mkdir -pv ~/.docker
cp -v {ca,cert,key}.pem ~/.docker
export DOCKER_HOST=tcp://<docker server private IP>:2376 DOCKER_TLS_VERIFY=1

docker version

```

# Lab working with docker content trust

Video 1 of 2

Introduction
------------

Previous

Previous Video

Next

Next Video

This video introduces the scenario for the lab and guides you toward some additional resources to help you complete it.

Working with Docker Content Trust
=================================

Introduction
------------

In this lab, we will work with Docker Content Trust (DCT) by signing a previously unsigned image and running it on a system that has DCT enabled.

Solution
--------

Log in to the Docker server using the credentials provided on the hands-on lab page:

`ssh cloud_user@<DOCKER_SERVER_PUBLIC_IP_ADDRESS>`

* Docker server
ssh cloud_user@174.129.75.120
o*0TktSq



### Generate a Trust Key and Add Yourself as a Signer to the New Repository

1.  Generate a trust key:
    
    `docker trust key generate docker`
    dockerkey
    
2.  Create a new passphrase for your key when prompted. (Make sure it's easy to remember, as we'll need it later.)
    
3.  Add yourself as a signer to the `ip-10-0-1-102:443/content-dca-tea` repository:
    
    `
    docker trust signer add --key docker.pub docker ip-10-0-1-102:443/content-dca-tea
    `
    repokey00
    
4.  Create passphrases for the new root key and new repository key when prompted.
    

### Create a New Tag for the Image, Sign It, and Push It to the Registry

1.  Create a new tag for the image:
    
    `docker tag linuxacademycontent/content-dca-tea:1 ip-10-0-1-102:443/content-dca-tea:1`
    
2.  Sign the image and push it to the registry:
    
    `docker trust sign ip-10-0-1-102:443/content-dca-tea:1`
    
3.  When prompted, enter the first passphrase you created earlier (the one for the trust key).
    
4.  Verify you can run the signed image:
    
    `docker run -d -p 8080:80 ip-10-0-1-102:443/content-dca-tea:1`
    
5.  To test the image further, query the tea list web service:
    
    `curl localhost:8080`
    
    We should see generated JSON data that contains a list of the various kinds of tea.
    

Conclusion
----------

Congratulations — you've completed this hands-on lab!